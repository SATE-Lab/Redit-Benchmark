2022-07-19 02:56:28,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = dn3/10.3.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.1
STARTUP_MSG:   classpath = /hadoop/hadoop-3.3.1/etc/hadoop:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/hadoop-annotations-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-util-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-io-2.8.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-http-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-util-ajax-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/curator-framework-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/woodstox-core-5.3.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-server-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-annotations-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-databind-2.10.5.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/slf4j-api-1.7.30.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jul-to-slf4j-1.7.30.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-io-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-core-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/json-smart-2.4.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/hadoop-auth-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/accessors-smart-2.4.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/zookeeper-jute-3.5.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-servlet-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/curator-client-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/zookeeper-3.5.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-security-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-xml-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/curator-recipes-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/stax2-api-4.2.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/jetty-webapp-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/MapReduce-0.1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/hadoop-common-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/hadoop-nfs-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/hadoop-common-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/reditrt-0.1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/aspectjrt-1.9.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/hadoop-registry-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/common/hadoop-kms-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/hadoop-annotations-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-util-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-http-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/curator-framework-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/woodstox-core-5.3.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-server-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-annotations-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-databind-2.10.5.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-io-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-core-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/json-smart-2.4.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/hadoop-auth-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/accessors-smart-2.4.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/zookeeper-jute-3.5.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-servlet-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/curator-client-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/zookeeper-3.5.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-security-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-xml-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/curator-recipes-4.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/netty-all-4.1.61.Final.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/jetty-webapp-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-client-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-client-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/hdfs/hadoop-hdfs-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.1-tests.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jetty-plus-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jetty-client-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jline-3.9.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/snakeyaml-1.26.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/asm-tree-9.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/websocket-client-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.10.5.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/websocket-api-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/websocket-servlet-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/websocket-common-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/asm-analysis-9.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/asm-commons-9.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jetty-jndi-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/objenesis-2.6.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jetty-annotations-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/jna-5.2.0.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/websocket-server-9.4.40.v20210413.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-services-api-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-api-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-common-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-common-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-client-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-services-core-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-server-router-3.3.1.jar:/hadoop/hadoop-3.3.1/share/hadoop/yarn/hadoop-yarn-registry-3.3.1.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r a3b9c37a397ad4188041dd80621bdeefc46885f2; compiled by 'ubuntu' on 2021-06-01T08:55Z
STARTUP_MSG:   java = 1.8.0_242
************************************************************/
2022-07-19 02:56:28,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2022-07-19 02:56:29,597 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-07-19 02:56:30,354 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/var/lib/hdfs/data
2022-07-19 02:56:30,563 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2022-07-19 02:56:30,739 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2022-07-19 02:56:30,739 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2022-07-19 02:56:31,486 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-07-19 02:56:31,515 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2022-07-19 02:56:31,552 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is dn3
2022-07-19 02:56:31,552 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2022-07-19 02:56:31,561 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2022-07-19 02:56:31,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2022-07-19 02:56:31,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 104857600 bytes/s
2022-07-19 02:56:31,618 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 100
2022-07-19 02:56:31,813 INFO org.eclipse.jetty.util.log: Logging initialized @6078ms to org.eclipse.jetty.util.log.Slf4jLog
2022-07-19 02:56:32,458 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2022-07-19 02:56:32,488 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2022-07-19 02:56:32,530 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2022-07-19 02:56:32,557 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2022-07-19 02:56:32,562 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2022-07-19 02:56:32,562 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2022-07-19 02:56:32,729 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46423
2022-07-19 02:56:32,738 INFO org.eclipse.jetty.server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_242-b08
2022-07-19 02:56:32,844 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2022-07-19 02:56:32,844 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2022-07-19 02:56:32,847 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2022-07-19 02:56:32,903 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@11d8ae8b{logs,/logs,file:///hadoop/hadoop-3.3.1/logs/,AVAILABLE}
2022-07-19 02:56:32,904 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f8a9499{static,/static,jar:file:/hadoop/hadoop-3.3.1/share/hadoop/common/MapReduce-0.1.0.jar!/webapps/static,AVAILABLE}
2022-07-19 02:56:39,153 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@60856961{datanode,/,file:///tmp/jetty-localhost-46423-MapReduce-0_1_0_jar-_-any-2336918101352661866/webapp/,AVAILABLE}{jar:file:/hadoop/hadoop-3.3.1/share/hadoop/common/MapReduce-0.1.0.jar!/webapps/datanode}
2022-07-19 02:56:39,182 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@55cf0d14{HTTP/1.1, (http/1.1)}{localhost:46423}
2022-07-19 02:56:39,183 INFO org.eclipse.jetty.server.Server: Started @13447ms
2022-07-19 02:56:39,468 WARN org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Got null for restCsrfPreventionFilter - will not do any filtering.
2022-07-19 02:56:39,673 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2022-07-19 02:56:39,704 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2022-07-19 02:56:39,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2022-07-19 02:56:39,705 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2022-07-19 02:56:39,803 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2022-07-19 02:56:39,850 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2022-07-19 02:56:40,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2022-07-19 02:56:40,796 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: mycluster
2022-07-19 02:56:40,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: mycluster
2022-07-19 02:56:40,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn1/10.3.0.2:8020 starting to offer service
2022-07-19 02:56:40,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn2/10.3.0.4:8020 starting to offer service
2022-07-19 02:56:40,953 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn3/10.3.0.3:8020 starting to offer service
2022-07-19 02:56:40,986 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2022-07-19 02:56:40,967 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2022-07-19 02:56:41,533 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2022-07-19 02:56:41,559 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/lib/hdfs/data/in_use.lock acquired by nodename 48@dn3
2022-07-19 02:56:41,560 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/var/lib/hdfs/data is not formatted for namespace 1692333321. Formatting...
2022-07-19 02:56:41,561 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-2b53bfcb-abbf-46b3-beb3-bd5ff1e74fef for directory /var/lib/hdfs/data 
2022-07-19 02:56:41,702 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1754811621-10.3.0.2-1658199377885
2022-07-19 02:56:41,703 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /var/lib/hdfs/data/current/BP-1754811621-10.3.0.2-1658199377885
2022-07-19 02:56:41,703 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/var/lib/hdfs/data and block pool id BP-1754811621-10.3.0.2-1658199377885 is not formatted. Formatting ...
2022-07-19 02:56:41,703 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1754811621-10.3.0.2-1658199377885 directory /var/lib/hdfs/data/current/BP-1754811621-10.3.0.2-1658199377885/current
2022-07-19 02:56:41,723 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1692333321;bpid=BP-1754811621-10.3.0.2-1658199377885;lv=-57;nsInfo=lv=-66;cid=CID-b4d6d607-54b1-463d-9aa1-c8a92b75ba89;nsid=1692333321;c=1658199377885;bpid=BP-1754811621-10.3.0.2-1658199377885;dnuuid=null
2022-07-19 02:56:41,726 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID da1da033-6ceb-40ed-b832-fe98b7788479
2022-07-19 02:56:41,795 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: The datanode lock is a read write lock
2022-07-19 02:56:42,213 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-2b53bfcb-abbf-46b3-beb3-bd5ff1e74fef
2022-07-19 02:56:42,213 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/var/lib/hdfs/data, StorageType: DISK
2022-07-19 02:56:42,216 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2022-07-19 02:56:42,236 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2022-07-19 02:56:42,267 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1754811621-10.3.0.2-1658199377885
2022-07-19 02:56:42,329 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1754811621-10.3.0.2-1658199377885 on volume /var/lib/hdfs/data...
2022-07-19 02:56:42,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn3/10.3.0.3:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:42,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn2/10.3.0.4:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:42,476 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1754811621-10.3.0.2-1658199377885 on /var/lib/hdfs/data: 139ms
2022-07-19 02:56:42,477 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1754811621-10.3.0.2-1658199377885: 209ms
2022-07-19 02:56:42,486 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1754811621-10.3.0.2-1658199377885 on volume /var/lib/hdfs/data...
2022-07-19 02:56:42,486 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /var/lib/hdfs/data/current/BP-1754811621-10.3.0.2-1658199377885/current/replicas doesn't exist 
2022-07-19 02:56:42,533 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1754811621-10.3.0.2-1658199377885 on volume /var/lib/hdfs/data: 47ms
2022-07-19 02:56:42,533 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1754811621-10.3.0.2-1658199377885: 48ms
2022-07-19 02:56:42,534 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /var/lib/hdfs/data
2022-07-19 02:56:42,586 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /var/lib/hdfs/data
2022-07-19 02:56:42,612 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1754811621-10.3.0.2-1658199377885 on volume /var/lib/hdfs/data
2022-07-19 02:56:42,619 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/var/lib/hdfs/data, DS-2b53bfcb-abbf-46b3-beb3-bd5ff1e74fef): finished scanning block pool BP-1754811621-10.3.0.2-1658199377885
2022-07-19 02:56:42,684 WARN org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value above 1000 ms/sec. Assuming default value of -1
2022-07-19 02:56:42,685 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting in 20930467ms with interval of 21600000ms and throttle limit of -1ms/s
2022-07-19 02:56:42,715 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/var/lib/hdfs/data, DS-2b53bfcb-abbf-46b3-beb3-bd5ff1e74fef): no suitable block pools found to scan.  Waiting 1814399894 ms.
2022-07-19 02:56:42,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn1/10.3.0.2:8020 beginning handshake with NN
2022-07-19 02:56:42,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn1/10.3.0.2:8020 successfully registered with NN
2022-07-19 02:56:42,938 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn1/10.3.0.2:8020 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2022-07-19 02:56:43,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x1009671dac5a7ba0 to namenode: nn1/10.3.0.2:8020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msecs to generate and 74 msecs for RPC and NN processing. Got back no commands.
2022-07-19 02:56:43,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn3/10.3.0.3:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:43,374 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn2/10.3.0.4:8020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:44,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn3/10.3.0.3:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:44,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn2/10.3.0.4:8020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:45,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn3/10.3.0.3:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:45,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn2/10.3.0.4:8020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2022-07-19 02:56:45,893 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn3/10.3.0.3:8020 beginning handshake with NN
2022-07-19 02:56:45,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn3/10.3.0.3:8020 successfully registered with NN
2022-07-19 02:56:45,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn3/10.3.0.3:8020 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2022-07-19 02:56:46,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8e6a7877ef119200 to namenode: nn3/10.3.0.3:8020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 38 msecs for RPC and NN processing. Got back no commands.
2022-07-19 02:56:46,079 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn2/10.3.0.4:8020 beginning handshake with NN
2022-07-19 02:56:46,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn2/10.3.0.4:8020 successfully registered with NN
2022-07-19 02:56:46,117 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn2/10.3.0.4:8020 using BLOCKREPORT_INTERVAL of 21600000msecs CACHEREPORT_INTERVAL of 10000msecs Initial delay: 0msecs; heartBeatInterval=3000
2022-07-19 02:56:46,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xe320c89d4d24cbc6 to namenode: nn2/10.3.0.4:8020,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msecs to generate and 22 msecs for RPC and NN processing. Got back no commands.
2022-07-19 02:57:00,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn1/10.3.0.2:8020 trying to claim ACTIVE state with txid=1
2022-07-19 02:57:00,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1754811621-10.3.0.2-1658199377885 (Datanode Uuid da1da033-6ceb-40ed-b832-fe98b7788479) service to nn1/10.3.0.2:8020
2022-07-19 02:57:04,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1754811621-10.3.0.2-1658199377885:blk_1073741825_1001 src: /10.3.0.1:48356 dest: /10.3.0.6:9866
2022-07-19 02:57:05,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.3.0.1:48356, dest: /10.3.0.6:9866, bytes: 441063, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1585867286_1, offset: 0, srvID: da1da033-6ceb-40ed-b832-fe98b7788479, blockid: BP-1754811621-10.3.0.2-1658199377885:blk_1073741825_1001, duration(ns): 130741027
2022-07-19 02:57:05,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1754811621-10.3.0.2-1658199377885:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.3.0.5:9866, 10.3.0.7:9866] terminating
2022-07-19 02:57:05,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1754811621-10.3.0.2-1658199377885:blk_1073741826_1002 src: /10.3.0.7:40870 dest: /10.3.0.6:9866
2022-07-19 02:57:05,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.3.0.7:40870, dest: /10.3.0.6:9866, bytes: 540254, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1585867286_1, offset: 0, srvID: da1da033-6ceb-40ed-b832-fe98b7788479, blockid: BP-1754811621-10.3.0.2-1658199377885:blk_1073741826_1002, duration(ns): 41271084
2022-07-19 02:57:05,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1754811621-10.3.0.2-1658199377885:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[10.3.0.5:9866] terminating
2022-07-19 02:57:09,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1754811621-10.3.0.2-1658199377885:blk_1073741827_1003 src: /10.3.0.2:40722 dest: /10.3.0.6:9866
2022-07-19 02:57:09,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /10.3.0.2:40722, dest: /10.3.0.6:9866, bytes: 106732, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1070999884_1, offset: 0, srvID: da1da033-6ceb-40ed-b832-fe98b7788479, blockid: BP-1754811621-10.3.0.2-1658199377885:blk_1073741827_1003, duration(ns): 44635945
2022-07-19 02:57:09,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1754811621-10.3.0.2-1658199377885:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[10.3.0.5:9866, 10.3.0.7:9866] terminating
2022-07-19 02:57:27,956 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "dn3/10.3.0.6"; destination host is: "nn1":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:543)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:677)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:879)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-07-19 02:57:27,960 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "dn3/10.3.0.6"; destination host is: "nn3":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:543)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:677)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:879)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
2022-07-19 02:57:28,132 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "dn3/10.3.0.6"; destination host is: "nn2":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1577)
	at org.apache.hadoop.ipc.Client.call(Client.java:1519)
	at org.apache.hadoop.ipc.Client.call(Client.java:1416)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:543)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:677)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:879)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1892)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1202)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1098)
