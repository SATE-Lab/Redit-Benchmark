18:37:48.179 [main] INFO io.redit.samples.kafka13563.SampleTest - wait for zookeeper...
18:37:48.179 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 startZookeeper...
18:37:48.192 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 startZookeeper...
18:37:48.192 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 startZookeeper...
18:37:58.221 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 checkStatus...
18:37:58.604 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
18:37:58.604 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower

18:37:59.605 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 checkStatus...
18:37:59.923 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
18:37:59.923 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower

18:38:00.924 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 checkStatus...
18:38:01.240 [main] INFO io.redit.samples.kafka13563.SampleTest - server3: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
18:38:01.240 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: leader

18:38:02.241 [main] INFO io.redit.samples.kafka13563.SampleTest - wait for kafka...
18:38:02.241 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 startKafka...
18:38:02.242 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 startKafka...
18:38:02.242 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 startKafka...
18:38:08.387 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: jps
18:38:08.387 [main] INFO io.redit.samples.kafka13563.SampleTest - 38 QuorumPeerMain
537 Jps
477 Kafka

18:38:09.383 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: jps
18:38:09.384 [main] INFO io.redit.samples.kafka13563.SampleTest - 35 QuorumPeerMain
474 Kafka
557 Jps

18:38:09.646 [main] INFO io.redit.samples.kafka13563.SampleTest - server3: jps
18:38:09.646 [main] INFO io.redit.samples.kafka13563.SampleTest - 481 Kafka
34 QuorumPeerMain
564 Jps

18:38:12.643 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: cd /kafka/kafka_2.13-2.7.1 && bin/kafka-topics.sh --bootstrap-server 10.5.0.4:9092,10.5.0.3:9092,10.5.0.2:9092 --create --replication-factor 3 --partitions 2 --topic TEST
18:38:12.643 [main] INFO io.redit.samples.kafka13563.SampleTest - Created topic TEST.

18:38:12.791 [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.5.0.4:9092, 10.5.0.3:9092, 10.5.0.2:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-TestGroup-1
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestGroup
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.VoidDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

18:38:12.799 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initializing the Kafka consumer
18:38:12.947 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
18:38:12.947 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
18:38:12.947 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1661683092946
18:38:12.948 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Kafka consumer initialized
18:38:12.949 [main] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Subscribed to partition(s): TEST-0
18:38:12.955 [main] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [10.5.0.4:9092, 10.5.0.3:9092, 10.5.0.2:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.VoidSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

18:38:12.966 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initialize connection to node 10.5.0.4:9092 (id: -1 rack: null) for sending metadata request
18:38:12.973 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: -1 rack: null) using address /10.5.0.4
18:38:12.983 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
18:38:12.998 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -1
18:38:13.000 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Overriding the default acks to all since idempotence is enabled.
18:38:13.003 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
18:38:13.003 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
18:38:13.003 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1661683093003
18:38:13.003 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
18:38:13.004 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
18:38:13.008 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Transition from state UNINITIALIZED to INITIALIZING
============ kafkacat :[kafkacat -b 10.5.0.4:9092 -L]==============
Metadata for all topics (from broker 0: 10.5.0.4:9092/0):
 3 brokers:
  broker 0 at 10.5.0.4:9092
  broker 2 at 10.5.0.2:9092
  broker 1 at 10.5.0.3:9092 (controller)
 1 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 1, leader 2, replicas: 2,0,1, isrs: 2,0,1
kafkaControllerId: 1
18:38:13.196 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: cd /kafka/kafka_2.13-2.7.1 && bin/kafka-server-stop.sh
18:38:13.196 [main] INFO io.redit.samples.kafka13563.SampleTest -
18:38:13.370 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node -1. Fetching API versions.
18:38:13.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node -1.
18:38:13.380 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Enqueuing transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1)
18:38:13.394 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 10.5.0.2:9092 (id: -3 rack: null) for sending metadata request
18:38:13.398 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=0) and timeout 30000 to node -1: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:13.396 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.2:9092 (id: -3 rack: null) using address /10.5.0.2
18:38:13.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -3
18:38:13.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -3. Fetching API versions.
18:38:13.426 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -3.
18:38:13.428 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -3: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:13.428 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.3:9092 (id: -2 rack: null) using address /10.5.0.3
18:38:13.453 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -2
18:38:13.458 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -2. Fetching API versions.
18:38:13.461 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -2.
18:38:13.461 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 30000 to node -2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:13.560 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0): org.apache.kafka.common.requests.ApiVersionsResponse@27fbf9ee
18:38:13.565 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node -3: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:13.567 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: -3 rack: null)
18:38:13.568 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=2) and timeout 30000 to node -3: {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:13.574 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node -1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=0): org.apache.kafka.common.requests.ApiVersionsResponse@2602c50e
18:38:13.576 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1): org.apache.kafka.common.requests.ApiVersionsResponse@23993ff4
18:38:13.577 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node -2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:13.583 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Sending transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1) to node 10.5.0.3:9092 (id: -2 rack: null) with correlation ID 3
18:38:13.584 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending INIT_PRODUCER_ID request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=4, clientId=producer-1, correlationId=3) and timeout 30000 to node -2: {transactional_id=null,transaction_timeout_ms=2147483647,producer_id=-1,producer_epoch=-1,_tagged_fields={}}
18:38:13.586 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.3 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:477)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:313)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
18:38:13.583 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node -1: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:13.586 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: -1 rack: null)
18:38:13.586 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=1) and timeout 30000 to node -1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:13.593 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node -1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=1): org.apache.kafka.common.requests.MetadataResponse@278c598f
18:38:13.598 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from null to epoch 1 from new metadata
18:38:13.599 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from null to epoch 1 from new metadata
18:38:13.599 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node -3 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=2): org.apache.kafka.common.requests.MetadataResponse@2a5ee7e8
18:38:13.600 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: FQEBqTmXRqS0GA5ZmrY3Pg
18:38:13.601 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:13.601 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -2 disconnected.
18:38:13.606 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Disconnected from -2. Will retry.
18:38:13.606 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Enqueuing transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1)
18:38:13.606 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.4:9092 (id: 0 rack: null) using address /10.5.0.4
18:38:13.608 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
18:38:13.609 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
18:38:13.610 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 0.
18:38:13.609 [pool-6-thread-1] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Cluster ID: FQEBqTmXRqS0GA5ZmrY3Pg
18:38:13.610 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:13.611 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=4) and timeout 30000 to node 0: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:13.621 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 0 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=4): org.apache.kafka.common.requests.ApiVersionsResponse@cfbe36c
18:38:13.625 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:13.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
18:38:13.646 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
18:38:13.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2. Fetching API versions.
18:38:13.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2.
18:38:13.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=3) and timeout 30000 to node 2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:13.657 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=3): org.apache.kafka.common.requests.ApiVersionsResponse@4eacbb77
18:38:13.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:13.661 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=2) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:13.726 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Sending transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1) to node 10.5.0.4:9092 (id: 0 rack: null) with correlation ID 5
18:38:13.726 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending INIT_PRODUCER_ID request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=4, clientId=producer-1, correlationId=5) and timeout 30000 to node 0: {transactional_id=null,transaction_timeout_ms=2147483647,producer_id=-1,producer_epoch=-1,_tagged_fields={}}
18:38:13.727 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 10.5.0.3:9092 (id: 1 rack: null) for sending metadata request
18:38:13.727 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.3:9092 (id: 1 rack: null) using address /10.5.0.3
18:38:13.728 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.3 disconnected
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:219)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.maybeSendAndPollTransactionalRequest(Sender.java:477)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:313)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
18:38:13.729 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 1 disconnected.
18:38:13.729 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node 1 (/10.5.0.3:9092) could not be established. Broker may not be available.
18:38:13.732 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received INIT_PRODUCER_ID response from node 0 for request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=4, clientId=producer-1, correlationId=5): InitProducerIdResponseData(throttleTimeMs=0, errorCode=0, producerId=1000, producerEpoch=0)
18:38:13.733 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 1000 with epoch 0
18:38:13.733 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Transition from state INITIALIZING to READY
18:38:13.750 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=2): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:13.750 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683093750, latencyMs=117, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=2), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:13.750 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:13.751 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:13.751 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.751 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=4) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:13.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=4): org.apache.kafka.common.requests.MetadataResponse@a85a5d3
18:38:13.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:13.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:13.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 3 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:13.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.759 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:13.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:13.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683093783, latencyMs=25, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:13.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:13.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:13.830 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:13.830 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=6) and timeout 30000 to node 0: {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:13.840 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 0 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=6): org.apache.kafka.common.requests.MetadataResponse@1e938f39
18:38:13.840 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 3 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:13.858 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.858 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=6) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:13.868 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=6): org.apache.kafka.common.requests.MetadataResponse@2af3f0cc
18:38:13.868 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:13.868 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:13.869 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 4 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:13.869 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.869 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:13.910 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:13.910 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683093910, latencyMs=41, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:13.910 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:13.910 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:13.970 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.971 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:13.971 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:13.971 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=9) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.006 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:14.007 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=7) and timeout 30000 to node 0: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.013 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 0 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=7): org.apache.kafka.common.requests.MetadataResponse@4195a87
18:38:14.014 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-0 from null to epoch 1 from new metadata
18:38:14.014 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-1 from null to epoch 1 from new metadata
18:38:14.017 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 4 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.025 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.025 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094025, latencyMs=55, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.025 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.025 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.028 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=9): org.apache.kafka.common.requests.MetadataResponse@475759ee
18:38:14.028 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.028 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.029 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 5 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.030 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.030 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094074, latencyMs=44, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.099 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
18:38:14.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
18:38:14.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 2. Fetching API versions.
18:38:14.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 2.
18:38:14.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=8) and timeout 30000 to node 2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:14.107 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=8): org.apache.kafka.common.requests.ApiVersionsResponse@7d505307
18:38:14.107 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node 2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:14.115 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId of partition TEST-1 set to 1000 with epoch 0. Reinitialize sequence at beginning.
18:38:14.115 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 0 being sent to partition TEST-1
18:38:14.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=11) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=11): org.apache.kafka.common.requests.MetadataResponse@73e50b6d
18:38:14.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 6 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.142 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=9) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:14.220 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.221 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094220, latencyMs=87, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.221 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.221 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=13) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.248 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=13): org.apache.kafka.common.requests.MetadataResponse@5695012d
18:38:14.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 7 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.310 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.310 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094310, latencyMs=58, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.310 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.310 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.350 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.350 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=15) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.367 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=15): org.apache.kafka.common.requests.MetadataResponse@306d1895
18:38:14.367 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.367 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.368 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 8 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.369 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.369 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.423 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094423, latencyMs=54, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.468 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.468 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=17) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.484 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=17): org.apache.kafka.common.requests.MetadataResponse@4d88af5f
18:38:14.485 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.485 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.485 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 9 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.485 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.485 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.604 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.604 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094604, latencyMs=119, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.604 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.605 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.605 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.605 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=19) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.615 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=19): org.apache.kafka.common.requests.MetadataResponse@16ed7be0
18:38:14.615 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.615 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.615 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 10 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.616 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.617 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094667, latencyMs=51, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.693 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=9): org.apache.kafka.common.requests.ProduceResponse@134bb41e
18:38:14.693 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 0
18:38:14.716 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.716 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=21) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.727 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=21): org.apache.kafka.common.requests.MetadataResponse@680f9c79
18:38:14.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.729 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 11 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.729 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.729 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.765 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094765, latencyMs=36, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.828 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.828 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=23) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.838 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=23): org.apache.kafka.common.requests.MetadataResponse@30fe985d
18:38:14.838 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.838 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.839 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 12 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.839 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.839 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.936 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.936 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094936, latencyMs=97, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.936 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.936 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.939 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.939 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=25) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:14.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=25): org.apache.kafka.common.requests.MetadataResponse@38042b4a
18:38:14.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:14.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:14.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 13 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:14.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:14.961 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:14.961 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683094961, latencyMs=19, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:14.961 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:14.961 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:14.964 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:14.965 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.011 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.012 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095011, latencyMs=46, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.013 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.013 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.043 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.046 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=28) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.071 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=28): org.apache.kafka.common.requests.MetadataResponse@51b3c545
18:38:15.071 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.071 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.072 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 14 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.072 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.072 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId of partition TEST-0 set to 1000 with epoch 0. Reinitialize sequence at beginning.
18:38:15.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 0 being sent to partition TEST-0
18:38:15.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=10) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:15.166 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.166 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095166, latencyMs=94, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.166 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.166 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=30) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=30): org.apache.kafka.common.requests.MetadataResponse@15cb935e
18:38:15.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 15 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.194 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.194 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095194, latencyMs=15, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.194 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.194 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=32) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.294 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=32): org.apache.kafka.common.requests.MetadataResponse@c0ca4d6
18:38:15.294 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.294 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.295 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 16 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.295 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.295 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.337 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.338 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095337, latencyMs=42, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.338 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.338 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.395 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.395 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=34) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.397 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=34): org.apache.kafka.common.requests.MetadataResponse@12773d7b
18:38:15.397 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.397 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.397 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 17 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.398 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.398 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.425 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095424, latencyMs=26, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.425 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.425 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.434 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=10): org.apache.kafka.common.requests.ProduceResponse@27c1a1e9
18:38:15.435 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 0
18:38:15.497 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.498 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=36) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.513 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=36): org.apache.kafka.common.requests.MetadataResponse@5da14b9d
18:38:15.513 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.514 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.514 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 18 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.514 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.514 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.544 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.544 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095544, latencyMs=30, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.544 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.544 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.614 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.614 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=38) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=38): org.apache.kafka.common.requests.MetadataResponse@14397214
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 19 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.618 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095641, latencyMs=23, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.718 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.718 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=40) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.725 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=40): org.apache.kafka.common.requests.MetadataResponse@7d7a5e51
18:38:15.725 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.725 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.725 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 20 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.726 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.726 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095761, latencyMs=35, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.826 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.826 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=42) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=42): org.apache.kafka.common.requests.MetadataResponse@564d3860
18:38:15.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 21 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.832 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.832 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.858 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.858 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095858, latencyMs=26, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.859 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.863 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.931 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.931 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=44) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:15.937 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=44): org.apache.kafka.common.requests.MetadataResponse@1e76c97
18:38:15.937 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:15.937 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:15.938 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 22 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:15.938 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.938 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.964 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.964 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095964, latencyMs=26, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.964 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.964 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:15.965 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:15.965 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=46) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:15.973 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=46): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:15.973 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683095973, latencyMs=8, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=46), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:15.973 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:15.973 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:16.038 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.038 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=47) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:16.041 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=47): org.apache.kafka.common.requests.MetadataResponse@5e11176d
18:38:16.042 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:16.042 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:16.042 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 23 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:16.042 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.042 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=48) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.063 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=48): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:16.063 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096063, latencyMs=21, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=48), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:16.063 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:16.064 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:16.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 1 being sent to partition TEST-1
18:38:16.101 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=11) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:16.113 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=11): org.apache.kafka.common.requests.ProduceResponse@3f81b06f
18:38:16.114 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 1
18:38:16.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=49) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:16.148 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=49): org.apache.kafka.common.requests.MetadataResponse@71b64228
18:38:16.148 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:16.148 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:16.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 24 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:16.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=50) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=50): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:16.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096245, latencyMs=96, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=50), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:16.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:16.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:16.248 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.248 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=51) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:16.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=51): org.apache.kafka.common.requests.MetadataResponse@4e07fa46
18:38:16.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:16.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:16.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 25 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.3:9092 (id: 1 rack: null)}
18:38:16.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=52) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=52): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
18:38:16.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096288, latencyMs=19, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=52), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
18:38:16.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
18:38:16.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
18:38:16.369 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.370 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=53) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:16.379 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=53): org.apache.kafka.common.requests.MetadataResponse@74bea4c5
18:38:16.380 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:16.380 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:16.380 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 26 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.4:9092 (id: 0 rack: null)}
18:38:16.380 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.380 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=54) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.439 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=54): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092)
18:38:16.439 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096439, latencyMs=59, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=54), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092))
18:38:16.440 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null)
18:38:16.440 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 2147483647 rack: null) using address /10.5.0.4
18:38:16.440 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetching committed offsets for partitions: [TEST-0]
18:38:16.446 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
18:38:16.448 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2147483647. Fetching API versions.
18:38:16.448 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2147483647.
18:38:16.448 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=56) and timeout 30000 to node 2147483647: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:16.456 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2147483647 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=56): org.apache.kafka.common.requests.ApiVersionsResponse@a20e30c
18:38:16.456 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2147483647: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:16.457 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=55) and timeout 30000 to node 2147483647: {group_id=TestGroup,topics=[{name=TEST,partition_indexes=[0],_tagged_fields={}}],require_stable=true,_tagged_fields={}}
18:38:16.467 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_FETCH response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=55): org.apache.kafka.common.requests.OffsetFetchResponse@76985968
18:38:16.467 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Offset fetch failed: This is not the correct coordinator.
18:38:16.467 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR.isDisconnected: false. Rediscovery will be attempted.
18:38:16.568 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.568 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=57) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.576 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=57): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092)
18:38:16.576 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096576, latencyMs=8, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=57), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092))
18:38:16.576 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null)
18:38:16.576 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: false. Rediscovery will be attempted.
18:38:16.676 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:16.676 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=58) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:16.681 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=58): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092)
18:38:16.681 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683096681, latencyMs=5, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=58), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092))
18:38:16.681 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null)
18:38:16.681 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 2147483647 rack: null) using address /10.5.0.4
18:38:16.682 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetching committed offsets for partitions: [TEST-0]
18:38:16.682 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
18:38:16.682 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2147483647. Fetching API versions.
18:38:16.682 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2147483647.
18:38:16.682 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=60) and timeout 30000 to node 2147483647: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:16.685 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2147483647 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=60): org.apache.kafka.common.requests.ApiVersionsResponse@557c7a55
18:38:16.687 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2147483647: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:16.687 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=59) and timeout 30000 to node 2147483647: {group_id=TestGroup,topics=[{name=TEST,partition_indexes=[0],_tagged_fields={}}],require_stable=true,_tagged_fields={}}
18:38:16.691 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_FETCH response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=59): org.apache.kafka.common.requests.OffsetFetchResponse@baa5d8e
18:38:16.691 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Found no committed offset for partition TEST-0
18:38:16.699 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending ListOffsetRequest ListOffsetRequestData(replicaId=-1, isolationLevel=0, topics=[ListOffsetTopic(name='TEST', partitions=[ListOffsetPartition(partitionIndex=0, currentLeaderEpoch=1, timestamp=-1, maxNumOffsets=1)])]) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:16.700 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 0 rack: null) using address /10.5.0.4
18:38:16.705 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
18:38:16.707 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 0. Fetching API versions.
18:38:16.707 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 0.
18:38:16.707 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=62) and timeout 30000 to node 0: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:16.726 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 0 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=62): org.apache.kafka.common.requests.ApiVersionsResponse@24433f0
18:38:16.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 0: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:16.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending LIST_OFFSETS request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=5, clientId=consumer-TestGroup-1, correlationId=61) and timeout 30000 to node 0: {replica_id=-1,isolation_level=0,topics=[{name=TEST,partitions=[{partition_index=0,current_leader_epoch=1,timestamp=-1}]}]}
18:38:16.737 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received LIST_OFFSETS response from node 0 for request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=5, clientId=consumer-TestGroup-1, correlationId=61): ListOffsetResponseData(throttleTimeMs=0, topics=[ListOffsetTopicResponse(name='TEST', partitions=[ListOffsetPartitionResponse(partitionIndex=0, errorCode=0, oldStyleOffsets=[], timestamp=-1, offset=1, leaderEpoch=1)])])
18:38:16.738 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Handling ListOffsetResponse response for TEST-0. Fetched offset 1, timestamp -1
18:38:16.739 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Not replacing existing epoch 1 with new epoch 1 for partition TEST-0
18:38:16.740 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Resetting offset for partition TEST-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}}.
18:38:16.743 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:16.743 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
18:38:16.744 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED FullFetchRequest(TEST-0) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:16.748 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=63) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=0,session_epoch=0,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=1,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:17.102 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 1 being sent to partition TEST-0
18:38:17.103 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=12) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:17.118 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=12): org.apache.kafka.common.requests.ProduceResponse@72edd35d
18:38:17.118 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 1
18:38:17.122 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=63): org.apache.kafka.common.requests.FetchResponse@1da6b5b0
18:38:17.122 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent a full fetch response that created a new incremental fetch session 401107416 with 1 response partition(s)
18:38:17.123 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 1 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=2, lastStableOffset = 2, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:17.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:17.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=1) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:17.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:17.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=64) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=1,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=2,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 1, CreateTime = 1661683097101, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:17.101Z)=================
18:38:17.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=64): org.apache.kafka.common.requests.FetchResponse@7d56012a
18:38:17.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:17.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:17.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=2) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:17.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:17.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=65) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=2,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:17.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=2, leaderEpoch=1, metadata=''}}
18:38:17.944 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=66) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=2,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:18.103 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 2 being sent to partition TEST-1
18:38:18.103 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=13) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:18.116 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=13): org.apache.kafka.common.requests.ProduceResponse@5c1ff7e2
18:38:18.116 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 2
18:38:18.136 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=65): org.apache.kafka.common.requests.FetchResponse@1d58a70
18:38:18.136 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:18.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:18.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=3) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:18.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:18.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=67) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=3,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:18.176 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=66): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:18.176 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 2 for partition TEST-0
18:38:18.177 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=2, leaderEpoch=1, metadata=''}}
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=67): org.apache.kafka.common.requests.FetchResponse@1b7f298d
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=4) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:18.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=68) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=4,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:19.104 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 2 being sent to partition TEST-0
18:38:19.105 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=14) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=68): org.apache.kafka.common.requests.FetchResponse@36d4b698
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 2 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=3, lastStableOffset = 3, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=5) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:19.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=69) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=5,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=3,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 2, CreateTime = 1661683099104, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:19.103Z)=================
18:38:19.130 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=14): org.apache.kafka.common.requests.ProduceResponse@767bdb61
18:38:19.130 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 2
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=69): org.apache.kafka.common.requests.FetchResponse@485336e5
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=6) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:19.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=70) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=6,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:20.105 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 3 being sent to partition TEST-1
18:38:20.105 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=15) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:20.121 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=15): org.apache.kafka.common.requests.ProduceResponse@44cb0f09
18:38:20.121 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 3
18:38:20.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=70): org.apache.kafka.common.requests.FetchResponse@7b458714
18:38:20.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:20.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:20.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=7) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:20.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:20.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=71) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=7,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:20.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=71): org.apache.kafka.common.requests.FetchResponse@1914eab0
18:38:20.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:20.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:20.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=8) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:20.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:20.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=72) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=8,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:21.106 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 3 being sent to partition TEST-0
18:38:21.106 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=16) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:21.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=72): org.apache.kafka.common.requests.FetchResponse@a67ef7c
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 3 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=4, lastStableOffset = 4, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=9) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:21.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=73) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=9,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=4,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 3, CreateTime = 1661683101105, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:21.105Z)=================
18:38:21.136 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=16): org.apache.kafka.common.requests.ProduceResponse@58204bf6
18:38:21.136 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 3
18:38:21.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=73): org.apache.kafka.common.requests.FetchResponse@5b5204cb
18:38:21.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:21.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:21.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=10) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:21.638 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:21.638 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=74) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=10,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:22.107 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 4 being sent to partition TEST-1
18:38:22.107 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=17) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:22.120 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=17): org.apache.kafka.common.requests.ProduceResponse@7b2317f7
18:38:22.120 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 4
18:38:22.144 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=74): org.apache.kafka.common.requests.FetchResponse@cf85592
18:38:22.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:22.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:22.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=11) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:22.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:22.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=75) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=11,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:22.648 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=75): org.apache.kafka.common.requests.FetchResponse@32876fd7
18:38:22.649 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:22.649 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:22.649 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=12) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:22.649 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:22.649 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=76) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=12,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:22.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=4, leaderEpoch=1, metadata=''}}
18:38:22.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=77) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=4,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:22.955 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=77): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:22.955 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 4 for partition TEST-0
18:38:22.955 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=4, leaderEpoch=1, metadata=''}}
18:38:23.108 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 4 being sent to partition TEST-0
18:38:23.108 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=18) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:23.119 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=76): org.apache.kafka.common.requests.FetchResponse@72e6af4
18:38:23.119 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:23.119 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 4 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=5, lastStableOffset = 5, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:23.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:23.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=13) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:23.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:23.120 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=78) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=13,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=5,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 4, CreateTime = 1661683103107, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:23.107Z)=================
18:38:23.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=18): org.apache.kafka.common.requests.ProduceResponse@53ab6b21
18:38:23.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 4
============ kafkacat :[kafkacat -b 10.5.0.4:9092 -L]==============
Metadata for all topics (from broker 0: 10.5.0.4:9092/0):
 2 brokers:
  broker 0 at 10.5.0.4:9092 (controller)
  broker 2 at 10.5.0.2:9092
 2 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 1, leader 2, replicas: 2,0,1, isrs: 2,0
  topic "__consumer_offsets" with 50 partitions:
    partition 0, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 1, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 2, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 3, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 4, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 5, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 6, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 7, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 8, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 9, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 10, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 11, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 12, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 13, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 14, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 15, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 16, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 17, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 18, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 19, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 20, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 21, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 22, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 23, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 24, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 25, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 26, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 27, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 28, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 29, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 30, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 31, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 32, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 33, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 34, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 35, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 36, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 37, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 38, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 39, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 40, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 41, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 42, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 43, leader 0, replicas: 0,1,2, isrs: 0,2
    partition 44, leader 2, replicas: 1,2,0, isrs: 2,0
    partition 45, leader 2, replicas: 2,1,0, isrs: 2,0
    partition 46, leader 0, replicas: 0,2,1, isrs: 0,2
    partition 47, leader 0, replicas: 1,0,2, isrs: 0,2
    partition 48, leader 2, replicas: 2,0,1, isrs: 2,0
    partition 49, leader 0, replicas: 0,1,2, isrs: 0,2
kafkaControllerId: 0
18:38:23.317 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: cd /kafka/kafka_2.13-2.7.1 && bin/bin/kafka-server-start.sh -daemon ./config/server.properties
18:38:23.317 [main] INFO io.redit.samples.kafka13563.SampleTest -
18:38:23.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=78): org.apache.kafka.common.requests.FetchResponse@4c914286
18:38:23.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:23.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:23.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=14) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:23.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:23.624 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=79) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=14,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:24.109 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 5 being sent to partition TEST-1
18:38:24.109 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=19) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:24.119 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=19): org.apache.kafka.common.requests.ProduceResponse@4f04951a
18:38:24.119 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 5
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=79): org.apache.kafka.common.requests.FetchResponse@28bca43
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=15) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:24.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=80) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=15,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:24.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=80): org.apache.kafka.common.requests.FetchResponse@bfbf412
18:38:24.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:24.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:24.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=16) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:24.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:24.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=81) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=16,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:25.110 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 5 being sent to partition TEST-0
18:38:25.110 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=20) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:25.121 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=81): org.apache.kafka.common.requests.FetchResponse@7ff64653
18:38:25.121 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:25.121 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 5 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=6, lastStableOffset = 6, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:25.121 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:25.122 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=17) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:25.122 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:25.122 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=82) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=17,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=6,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 5, CreateTime = 1661683105109, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:25.109Z)=================
18:38:25.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=20): org.apache.kafka.common.requests.ProduceResponse@15a118f7
18:38:25.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 5
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=82): org.apache.kafka.common.requests.FetchResponse@3935be59
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=18) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:25.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=83) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=18,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:26.111 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 6 being sent to partition TEST-1
18:38:26.112 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=21) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:26.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=21): org.apache.kafka.common.requests.ProduceResponse@765e391b
18:38:26.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 6
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=83): org.apache.kafka.common.requests.FetchResponse@6530b2ee
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=19) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:26.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=84) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=19,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:26.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=84): org.apache.kafka.common.requests.FetchResponse@31bf913e
18:38:26.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:26.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:26.646 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=20) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:26.647 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:26.647 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=85) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=20,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:27.112 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 6 being sent to partition TEST-0
18:38:27.112 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=22) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=85): org.apache.kafka.common.requests.FetchResponse@7cb68d84
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 6 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=7, lastStableOffset = 7, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=21) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:27.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:27.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=86) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=21,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=7,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 6, CreateTime = 1661683107111, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:27.111Z)=================
18:38:27.130 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=22): org.apache.kafka.common.requests.ProduceResponse@7ea4b692
18:38:27.130 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 6
18:38:27.631 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=86): org.apache.kafka.common.requests.FetchResponse@68e5233d
18:38:27.631 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:27.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:27.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=22) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:27.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:27.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=87) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=22,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:27.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=7, leaderEpoch=1, metadata=''}}
18:38:27.944 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=88) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=7,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:27.954 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=88): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:27.954 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 7 for partition TEST-0
18:38:27.954 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=7, leaderEpoch=1, metadata=''}}
18:38:28.113 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 7 being sent to partition TEST-1
18:38:28.114 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=23) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:28.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=23): org.apache.kafka.common.requests.ProduceResponse@15634019
18:38:28.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 7
18:38:28.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=87): org.apache.kafka.common.requests.FetchResponse@8224b0d
18:38:28.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:28.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:28.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=23) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:28.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:28.141 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=89) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=23,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=89): org.apache.kafka.common.requests.FetchResponse@45d91d56
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=24) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:28.645 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=90) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=24,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:29.114 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 7 being sent to partition TEST-0
18:38:29.114 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=24) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=90): org.apache.kafka.common.requests.FetchResponse@d4b72c4
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 7 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=8, lastStableOffset = 8, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=25) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:29.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:29.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=91) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=25,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=8,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 7, CreateTime = 1661683109113, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:29.113Z)=================
18:38:29.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=24): org.apache.kafka.common.requests.ProduceResponse@89894e2
18:38:29.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 7
18:38:29.631 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=91): org.apache.kafka.common.requests.FetchResponse@4cf6549b
18:38:29.631 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:29.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:29.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=26) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:29.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:29.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=92) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=26,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:30.115 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 8 being sent to partition TEST-1
18:38:30.115 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=25) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:30.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=25): org.apache.kafka.common.requests.ProduceResponse@f09e20b
18:38:30.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 8
18:38:30.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=92): org.apache.kafka.common.requests.FetchResponse@5696142b
18:38:30.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:30.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:30.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=27) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:30.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:30.136 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=93) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=27,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:30.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=93): org.apache.kafka.common.requests.FetchResponse@5ba89002
18:38:30.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:30.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:30.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=28) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:30.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:30.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=94) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=28,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:31.116 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 8 being sent to partition TEST-0
18:38:31.117 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=26) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:31.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=94): org.apache.kafka.common.requests.FetchResponse@da304e1
18:38:31.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=26): org.apache.kafka.common.requests.ProduceResponse@54c2d55e
18:38:31.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 8
18:38:31.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:31.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 8 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=9, lastStableOffset = 9, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:31.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:31.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=29) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:31.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:31.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=95) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=29,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=9,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 8, CreateTime = 1661683111115, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:31.115Z)=================
18:38:31.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=95): org.apache.kafka.common.requests.FetchResponse@738fdb42
18:38:31.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:31.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:31.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=30) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:31.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:31.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=96) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=30,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:32.117 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 9 being sent to partition TEST-1
18:38:32.117 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=27) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:32.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=27): org.apache.kafka.common.requests.ProduceResponse@5b2e2457
18:38:32.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 9
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=96): org.apache.kafka.common.requests.FetchResponse@15deae54
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=31) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:32.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=97) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=31,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:32.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=97): org.apache.kafka.common.requests.FetchResponse@a69046d
18:38:32.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 0 response partition(s), 1 implied partition(s)
18:38:32.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:32.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=32) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:32.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:32.642 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=98) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=32,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:32.944 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=9, leaderEpoch=1, metadata=''}}
18:38:32.945 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=99) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=9,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:32.953 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=99): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:32.954 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 9 for partition TEST-0
18:38:32.954 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=9, leaderEpoch=1, metadata=''}}
18:38:33.117 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 9 being sent to partition TEST-0
18:38:33.117 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=28) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=98): org.apache.kafka.common.requests.FetchResponse@1ff89dcd
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 9 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=10, lastStableOffset = 10, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=33) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=100) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=33,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=10,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 9, CreateTime = 1661683113117, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:33.117Z)=================
18:38:33.136 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=28): org.apache.kafka.common.requests.ProduceResponse@17dd9454
18:38:33.136 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 9
18:38:33.397 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: cd /kafka/kafka_2.13-2.7.1 && bin/kafka-server-stop.sh
18:38:33.397 [main] INFO io.redit.samples.kafka13563.SampleTest -
18:38:33.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=100): org.apache.kafka.common.requests.FetchResponse@12a010bb
18:38:33.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.636 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=34) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.637 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=102) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:33.638 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=101) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=34,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=101): org.apache.kafka.common.requests.FetchResponse@72eca0b5
18:38:33.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=35) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=103) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=35,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.651 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=102): org.apache.kafka.common.requests.MetadataResponse@306488e9
18:38:33.651 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
18:38:33.651 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:33.651 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 27 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,1,2, isr=0,2, offlineReplicas=1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.4:9092 (id: 0 rack: null)}
18:38:33.657 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=103): org.apache.kafka.common.requests.FetchResponse@6b297ddd
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=36) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.658 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=104) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=36,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=104): org.apache.kafka.common.requests.FetchResponse@799e8dcb
18:38:33.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.660 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.661 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=37) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.661 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.661 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=105) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=37,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.665 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=105): org.apache.kafka.common.requests.FetchResponse@6e606345
18:38:33.665 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.665 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=38) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=106) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=38,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=106): org.apache.kafka.common.requests.FetchResponse@7ad78da0
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=39) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.669 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=107) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=39,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.674 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=107): org.apache.kafka.common.requests.FetchResponse@5ab0c0b2
18:38:33.674 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=40) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.675 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=108) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=40,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.679 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=108): org.apache.kafka.common.requests.FetchResponse@57cdeefa
18:38:33.679 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.679 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.680 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.680 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.680 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=41) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.680 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.681 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=109) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=41,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.684 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=109): org.apache.kafka.common.requests.FetchResponse@3adac50d
18:38:33.684 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.684 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.685 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.685 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.686 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=42) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.686 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.686 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=110) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=42,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.694 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=110): org.apache.kafka.common.requests.FetchResponse@7c26e57b
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=43) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.695 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=111) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=43,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=111): org.apache.kafka.common.requests.FetchResponse@204f1f1d
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=44) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.701 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.702 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=112) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=44,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.705 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=112): org.apache.kafka.common.requests.FetchResponse@184d9fd0
18:38:33.705 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.705 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.705 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.706 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.706 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=45) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.706 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.706 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=113) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=45,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.727 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=113): org.apache.kafka.common.requests.FetchResponse@74d3d379
18:38:33.727 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.727 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.727 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
18:38:33.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=401107416, epoch=46) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:33.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
18:38:33.728 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=114) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=401107416,session_epoch=46,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=115) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:33.755 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=115): org.apache.kafka.common.requests.MetadataResponse@3f15fda5
18:38:33.755 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 2 from new metadata
18:38:33.755 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
18:38:33.756 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 28 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,1,2, isr=2, offlineReplicas=0,1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[1], replicas=2,0,1, isr=2,0, offlineReplicas=1)], controller=10.5.0.4:9092 (id: 0 rack: null)}
18:38:33.759 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_FOR_LEADER_EPOCH request with header RequestHeader(apiKey=OFFSET_FOR_LEADER_EPOCH, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=116) and timeout 30000 to node 2: {replica_id=-1,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,leader_epoch=1}]}]}
18:38:33.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=114): org.apache.kafka.common.requests.FetchResponse@7f5f2cca
18:38:33.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 401107416 with 1 response partition(s)
18:38:33.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:33.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Ignoring fetched records for partition TEST-0 since it no longer has valid position
18:38:33.764 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_FOR_LEADER_EPOCH response from node 2 for request with header RequestHeader(apiKey=OFFSET_FOR_LEADER_EPOCH, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=116): (type=OffsetsForLeaderEpochResponse, , throttleTimeMs=0, epochEndOffsetsByPartition={TEST-0=EpochEndOffset{error=NONE, leaderEpoch=1, endOffset=10}})
18:38:33.765 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Handling OffsetsForLeaderEpoch response for TEST-0. Got offset 10 for epoch 1
18:38:33.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 2 with 1 partition(s).
18:38:33.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED FullFetchRequest(TEST-0) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=117) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=0,session_epoch=0,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=10,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:33.840 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1292)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1233)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:139)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
18:38:33.841 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1292)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1233)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:139)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
18:38:33.841 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 disconnected.
18:38:33.841 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node -1 disconnected.
18:38:33.856 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.856 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=118) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:33.871 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1292)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1233)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:139)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
18:38:33.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2147483647 disconnected.
18:38:33.872 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:325)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
18:38:33.873 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 0 disconnected.
18:38:33.873 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:33.873 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=29) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:33.881 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=29): org.apache.kafka.common.requests.MetadataResponse@5784251e
18:38:33.882 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-0 from 1 to epoch 2 from new metadata
18:38:33.882 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-1 from 1 to epoch 2 from new metadata
18:38:33.882 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 5 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,1,2, isr=2, offlineReplicas=0,1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[2], replicas=2,0,1, isr=2, offlineReplicas=0,1)], controller=10.5.0.4:9092 (id: 0 rack: null)}
18:38:34.118 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 10 being sent to partition TEST-1
18:38:34.119 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=30) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:34.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=30): org.apache.kafka.common.requests.ProduceResponse@152e7295
18:38:34.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 10
18:38:34.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=117): org.apache.kafka.common.requests.FetchResponse@5bbc5b86
18:38:34.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent a full fetch response that created a new incremental fetch session 1439410290 with 1 response partition(s)
18:38:34.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=10, lastStableOffset = 10, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
18:38:34.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:34.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=1) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:34.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:34.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=119) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=1,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:34.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=118): org.apache.kafka.common.requests.MetadataResponse@5b1d0d7d
18:38:34.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 2 to epoch 2 from new metadata
18:38:34.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 2 from new metadata
18:38:34.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 29 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,1,2, isr=2, offlineReplicas=0,1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[2], replicas=2,0,1, isr=2, offlineReplicas=0,1)], controller=10.5.0.4:9092 (id: 0 rack: null)}
18:38:34.789 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=119): org.apache.kafka.common.requests.FetchResponse@2f06a65e
18:38:34.790 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:34.790 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:34.790 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=2) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:34.790 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:34.790 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=120) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=2,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:35.120 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 10 being sent to partition TEST-0
18:38:35.120 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=31) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:35.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=31): org.apache.kafka.common.requests.ProduceResponse@3f08e0fb
18:38:35.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 10
18:38:35.124 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=120): org.apache.kafka.common.requests.FetchResponse@78b6e316
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 1 response partition(s)
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=11, lastStableOffset = 11, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=3) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:35.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=121) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=3,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=11,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 10, CreateTime = 1661683115119, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:35.119Z)=================
18:38:35.628 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=121): org.apache.kafka.common.requests.FetchResponse@41efe7ed
18:38:35.629 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:35.629 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:35.629 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=4) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:35.629 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:35.630 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=122) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=4,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:36.121 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 11 being sent to partition TEST-1
18:38:36.121 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=32) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:36.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=32): org.apache.kafka.common.requests.ProduceResponse@440cac7a
18:38:36.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 11
18:38:36.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=122): org.apache.kafka.common.requests.FetchResponse@722a7c48
18:38:36.132 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:36.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:36.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=5) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:36.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:36.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=123) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=5,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=123): org.apache.kafka.common.requests.FetchResponse@68840005
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=6) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:36.635 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=124) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=6,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:37.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 11 being sent to partition TEST-0
18:38:37.122 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=33) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:37.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=33): org.apache.kafka.common.requests.ProduceResponse@3256dd30
18:38:37.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 11
18:38:37.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=124): org.apache.kafka.common.requests.FetchResponse@27e5f050
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 1 response partition(s)
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 11 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=12, lastStableOffset = 12, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=7) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:37.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=125) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=7,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=12,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 11, CreateTime = 1661683117121, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:37.121Z)=================
18:38:37.631 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=125): org.apache.kafka.common.requests.FetchResponse@190bbbce
18:38:37.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:37.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:37.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=8) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:37.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:37.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=126) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=8,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:37.948 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
18:38:37.948 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 2147483647 rack: null) using address /10.5.0.4
18:38:37.949 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:219)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:306)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsAsync(ConsumerCoordinator.java:953)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.doAutoCommitOffsetsAsync(ConsumerCoordinator.java:1041)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsAsync(ConsumerCoordinator.java:1032)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:529)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1257)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1226)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:139)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
18:38:37.949 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2147483647 disconnected.
18:38:37.949 [pool-6-thread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection to node 2147483647 (/10.5.0.4:9092) could not be established. Broker may not be available.
18:38:37.949 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Cancelled request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=127) due to node 2147483647 being disconnected
18:38:37.949 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
18:38:37.949 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:37.949 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=128) and timeout 30000 to node 2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
18:38:37.950 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}} failed due to retriable error: {}
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException: null
18:38:38.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
18:38:38.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:38.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=129) and timeout 30000 to node 2: {key=TestGroup,key_type=0,_tagged_fields={}}
18:38:38.123 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 12 being sent to partition TEST-1
18:38:38.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=34) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:38.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=34): org.apache.kafka.common.requests.ProduceResponse@548aab35
18:38:38.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 12
18:38:38.134 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=126): org.apache.kafka.common.requests.FetchResponse@3c50ef82
18:38:38.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:38.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:38.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=9) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:38.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:38.135 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=130) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=9,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:38.136 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=128): org.apache.kafka.common.requests.MetadataResponse@16fcea17
18:38:38.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 2 to epoch 2 from new metadata
18:38:38.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 2 to epoch 2 from new metadata
18:38:38.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 30 to MetadataCache{clusterId='FQEBqTmXRqS0GA5ZmrY3Pg', nodes={2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,1,2, isr=2, offlineReplicas=0,1), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[2], replicas=2,0,1, isr=2, offlineReplicas=0,1)], controller=10.5.0.2:9092 (id: 2 rack: null)}
18:38:38.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 2 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=129): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=2, host='10.5.0.2', port=9092)
18:38:38.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1661683118138, latencyMs=87, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=129), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=2, host='10.5.0.2', port=9092))
18:38:38.138 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.2:9092 (id: 2147483645 rack: null)
18:38:38.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.2:9092 (id: 2147483645 rack: null) using address /10.5.0.2
18:38:38.140 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483645
18:38:38.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2147483645. Fetching API versions.
18:38:38.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2147483645.
18:38:38.140 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=132) and timeout 30000 to node 2147483645: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
18:38:38.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2147483645 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=132): org.apache.kafka.common.requests.ApiVersionsResponse@7e52df9f
18:38:38.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2147483645: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
18:38:38.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=131) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=12,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:38.167 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=131): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:38.167 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 12 for partition TEST-0
18:38:38.167 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
18:38:38.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=130): org.apache.kafka.common.requests.FetchResponse@502586f1
18:38:38.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:38.643 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:38.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=10) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:38.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:38.644 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=133) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=10,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:39.124 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 12 being sent to partition TEST-0
18:38:39.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=35) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:39.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=35): org.apache.kafka.common.requests.ProduceResponse@2cfd8667
18:38:39.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 12
18:38:39.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=133): org.apache.kafka.common.requests.FetchResponse@42ee496f
18:38:39.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 1 response partition(s)
18:38:39.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 12 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=13, lastStableOffset = 13, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:39.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:39.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=11) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:39.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:39.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=134) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=11,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=13,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 12, CreateTime = 1661683119124, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:39.124Z)=================
18:38:39.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=134): org.apache.kafka.common.requests.FetchResponse@441a1ce8
18:38:39.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:39.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:39.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=12) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:39.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:39.633 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=135) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=12,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:40.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 13 being sent to partition TEST-1
18:38:40.125 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=36) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:40.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=36): org.apache.kafka.common.requests.ProduceResponse@db380fe
18:38:40.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 13
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=135): org.apache.kafka.common.requests.FetchResponse@2cdc9dd3
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=13) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:40.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=136) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=13,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:40.640 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=136): org.apache.kafka.common.requests.FetchResponse@50b284b7
18:38:40.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:40.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:40.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=14) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:40.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:40.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=137) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=14,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:41.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 13 being sent to partition TEST-0
18:38:41.126 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=37) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:41.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=37): org.apache.kafka.common.requests.ProduceResponse@9087325
18:38:41.129 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 13
18:38:41.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=137): org.apache.kafka.common.requests.FetchResponse@60271aff
18:38:41.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 1 response partition(s)
18:38:41.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 13 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=14, lastStableOffset = 14, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:41.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:41.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=15) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:41.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:41.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=138) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=15,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=14,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 13, CreateTime = 1661683121125, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:41.125Z)=================
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=138): org.apache.kafka.common.requests.FetchResponse@744eb74f
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=16) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:41.634 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=139) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=16,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:42.127 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 14 being sent to partition TEST-1
18:38:42.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=38) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
18:38:42.132 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=38): org.apache.kafka.common.requests.ProduceResponse@85ab232
18:38:42.132 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-1 to 14
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=139): org.apache.kafka.common.requests.FetchResponse@3cb49e10
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=17) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:42.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=140) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=17,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=140): org.apache.kafka.common.requests.FetchResponse@78e7320d
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 0 response partition(s), 1 implied partition(s)
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=18) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:42.641 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=141) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=18,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
18:38:43.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=14, leaderEpoch=2, metadata=''}}
18:38:43.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=142) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=14,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
18:38:43.055 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=142): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
18:38:43.055 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 14 for partition TEST-0
18:38:43.055 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=14, leaderEpoch=2, metadata=''}}
18:38:43.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 1000 and producerEpoch 0 to batch with base sequence 14 being sent to partition TEST-0
18:38:43.128 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=39) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
18:38:43.133 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=39): org.apache.kafka.common.requests.ProduceResponse@48d4c3e0
18:38:43.133 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 1000; Set last ack'd sequence number for topic-partition TEST-0 to 14
18:38:43.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=141): org.apache.kafka.common.requests.FetchResponse@204f3f0c
18:38:43.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 1439410290 with 1 response partition(s)
18:38:43.133 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 14 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=15, lastStableOffset = 15, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
18:38:43.134 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=15, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
18:38:43.134 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=1439410290, epoch=19) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
18:38:43.134 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
18:38:43.134 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=143) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=1439410290,session_epoch=19,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=15,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
=================ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 14, CreateTime = 1661683123128, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-08-28T10:38:43.128Z)=================
18:38:43.397 [main] INFO io.redit.samples.kafka13563.SampleTest - completed !!!
