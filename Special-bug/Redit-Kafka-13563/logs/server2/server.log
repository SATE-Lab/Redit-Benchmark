[2022-09-08 03:02:25,016] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-09-08 03:02:25,596] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-09-08 03:02:25,765] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-09-08 03:02:25,782] INFO starting (kafka.server.KafkaServer)
[2022-09-08 03:02:25,782] INFO Connecting to zookeeper on 10.5.0.4:2181,10.5.0.3:2181,10.5.0.2:2181 (kafka.server.KafkaServer)
[2022-09-08 03:02:25,811] INFO [ZooKeeperClient Kafka server] Initializing a new session to 10.5.0.4:2181,10.5.0.3:2181,10.5.0.2:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-09-08 03:02:25,828] INFO Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,828] INFO Client environment:host.name=server2 (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,828] INFO Client environment:java.version=1.8.0_242 (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,829] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,829] INFO Client environment:java.home=/usr/local/openjdk-8/jre (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,829] INFO Client environment:java.class.path=/kafka/kafka_2.13-2.7.1/bin/../libs/activation-1.1.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/argparse4j-0.7.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/audience-annotations-0.5.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/commons-cli-1.4.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/commons-lang3-3.8.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-api-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-basic-auth-extension-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-file-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-json-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-mirror-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-mirror-client-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-runtime-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/connect-transforms-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/hk2-api-2.6.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/hk2-locator-2.6.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/hk2-utils-2.6.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-annotations-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-core-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-databind-2.10.5.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-dataformat-csv-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-jaxrs-base-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-module-paranamer-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.inject-2.6.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/javassist-3.25.0-GA.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/javassist-3.26.0-GA.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/javax.servlet-api-3.1.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jaxb-api-2.3.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-client-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-common-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-container-servlet-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-container-servlet-core-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-hk2-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-media-jaxb-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jersey-server-2.31.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-client-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-continuation-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-http-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-io-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-security-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-server-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-servlet-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-servlets-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-util-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jetty-util-ajax-9.4.38.v20210224.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/jopt-simple-5.0.4.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-clients-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-log4j-appender-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-raft-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-streams-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-streams-examples-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-streams-scala_2.13-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-streams-test-utils-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka-tools-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka_2.13-2.7.1-sources.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/kafka_2.13-2.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/log4j-1.2.17.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/lz4-java-1.7.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/maven-artifact-3.6.3.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/metrics-core-2.2.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-buffer-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-codec-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-common-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-handler-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-resolver-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-transport-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-transport-native-epoll-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/netty-transport-native-unix-common-4.1.59.Final.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/paranamer-2.8.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/plexus-utils-3.2.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/reflections-0.9.12.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/rocksdbjni-5.18.4.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/scala-collection-compat_2.13-2.2.0.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/scala-library-2.13.3.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/scala-logging_2.13-3.9.2.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/scala-reflect-2.13.3.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/slf4j-api-1.7.30.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/slf4j-log4j12-1.7.30.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/snappy-java-1.1.7.7.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/zookeeper-3.5.9.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/zookeeper-jute-3.5.9.jar:/kafka/kafka_2.13-2.7.1/bin/../libs/zstd-jni-1.4.5-6.jar (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:os.version=5.15.0-46-generic (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,831] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,832] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,832] INFO Client environment:user.dir=/kafka/kafka_2.13-2.7.1 (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,832] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,832] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,832] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,889] INFO Initiating client connection, connectString=10.5.0.4:2181,10.5.0.3:2181,10.5.0.2:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@498d318c (org.apache.zookeeper.ZooKeeper)
[2022-09-08 03:02:25,897] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-09-08 03:02:25,902] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2022-09-08 03:02:25,906] INFO Opening socket connection to server redit_sample-kafka_server1_1662606125.redit_sample-kafka_1662606125/10.5.0.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-09-08 03:02:25,912] INFO Socket connection established, initiating session, client: /10.5.0.3:58534, server: redit_sample-kafka_server1_1662606125.redit_sample-kafka_1662606125/10.5.0.4:2181 (org.apache.zookeeper.ClientCnxn)
[2022-09-08 03:02:25,921] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-09-08 03:02:25,972] INFO Session establishment complete on server redit_sample-kafka_server1_1662606125.redit_sample-kafka_1662606125/10.5.0.4:2181, sessionid = 0x100003c3ee30000, negotiated timeout = 120000 (org.apache.zookeeper.ClientCnxn)
[2022-09-08 03:02:25,979] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-09-08 03:02:26,279] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-09-08 03:02:26,317] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2022-09-08 03:02:26,320] INFO Cleared cache (kafka.server.FinalizedFeatureCache)
[2022-09-08 03:02:26,730] INFO Cluster ID = -xzXV6INQZuCQMvamkAusg (kafka.server.KafkaServer)
[2022-09-08 03:02:26,754] WARN No meta.properties file under dir /kafka/kafka_2.13-2.7.1/logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-09-08 03:02:26,903] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://10.5.0.3:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka_2.13-2.7.1/logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 10.5.0.4:2181,10.5.0.3:2181,10.5.0.2:2181
	zookeeper.connection.timeout.ms = 60000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-09-08 03:02:26,920] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.7-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://10.5.0.3:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /kafka/kafka_2.13-2.7.1/logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.7-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = 10.5.0.4:2181,10.5.0.3:2181,10.5.0.2:2181
	zookeeper.connection.timeout.ms = 60000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-09-08 03:02:26,992] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-09-08 03:02:26,993] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-09-08 03:02:26,996] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-09-08 03:02:27,011] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-09-08 03:02:27,048] INFO Loading logs from log dirs ArraySeq(/kafka/kafka_2.13-2.7.1/logs) (kafka.log.LogManager)
[2022-09-08 03:02:27,050] INFO Attempting recovery for all logs in /kafka/kafka_2.13-2.7.1/logs since no clean shutdown file was found (kafka.log.LogManager)
[2022-09-08 03:02:27,057] INFO Loaded 0 logs in 9ms. (kafka.log.LogManager)
[2022-09-08 03:02:27,092] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-09-08 03:02:27,097] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-09-08 03:02:28,287] INFO Created ConnectionAcceptRate sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2022-09-08 03:02:28,290] INFO Created ConnectionAcceptRate-PLAINTEXT sensor, quotaLimit=2147483647 (kafka.network.ConnectionQuotas)
[2022-09-08 03:02:28,293] INFO Updated PLAINTEXT max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-09-08 03:02:28,302] INFO Awaiting socket connections on 10.5.0.3:9092. (kafka.network.Acceptor)
[2022-09-08 03:02:28,406] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-09-08 03:02:28,507] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,508] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,508] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,526] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,547] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-09-08 03:02:28,565] INFO [broker-1-to-controller-send-thread]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-09-08 03:02:28,619] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-09-08 03:02:28,701] INFO Stat of the created znode at /brokers/ids/1 is: 4294967357,4294967357,1662606148690,1662606148690,1,0,0,72057852791029760,200,0,4294967357
 (kafka.zk.KafkaZkClient)
[2022-09-08 03:02:28,701] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://10.5.0.3:9092, czxid (broker epoch): 4294967357 (kafka.zk.KafkaZkClient)
[2022-09-08 03:02:28,906] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,910] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,910] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:28,957] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-09-08 03:02:28,957] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-09-08 03:02:29,013] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2022-09-08 03:02:29,066] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-09-08 03:02:29,075] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-09-08 03:02:29,095] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2022-09-08 03:02:29,105] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-09-08 03:02:29,261] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-09-08 03:02:29,312] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-09-08 03:02:29,341] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-09-08 03:02:29,378] INFO [SocketServer brokerId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-09-08 03:02:29,397] INFO [SocketServer brokerId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-09-08 03:02:29,398] INFO [SocketServer brokerId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-09-08 03:02:29,414] INFO Kafka version: 2.7.1 (org.apache.kafka.common.utils.AppInfoParser)
[2022-09-08 03:02:29,414] INFO Kafka commitId: 61dbce85d0d41457 (org.apache.kafka.common.utils.AppInfoParser)
[2022-09-08 03:02:29,414] INFO Kafka startTimeMs: 1662606149398 (org.apache.kafka.common.utils.AppInfoParser)
[2022-09-08 03:02:29,416] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-09-08 03:02:29,915] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker 2 (kafka.server.BrokerToControllerRequestThread)
[2022-09-08 03:02:35,788] INFO [Log partition=TEST-1, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:35,825] INFO Created log for partition TEST-1 in /kafka/kafka_2.13-2.7.1/logs/TEST-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:35,826] INFO [Partition TEST-1 broker=1] No checkpointed highwatermark is found for partition TEST-1 (kafka.cluster.Partition)
[2022-09-08 03:02:35,827] INFO [Partition TEST-1 broker=1] Log loaded for partition TEST-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:35,847] INFO [Log partition=TEST-0, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:35,848] INFO Created log for partition TEST-0 in /kafka/kafka_2.13-2.7.1/logs/TEST-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:35,848] INFO [Partition TEST-0 broker=1] No checkpointed highwatermark is found for partition TEST-0 (kafka.cluster.Partition)
[2022-09-08 03:02:35,848] INFO [Partition TEST-0 broker=1] Log loaded for partition TEST-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:35,856] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(TEST-0, TEST-1) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:35,948] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:35,950] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(TEST-0 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:35,964] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition TEST-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:35,977] INFO [Log partition=TEST-0, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:35,989] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(TEST-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:36,004] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:36,004] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition TEST-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:36,004] INFO [Log partition=TEST-1, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:36,221] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition TEST-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:36,231] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition TEST-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:37,474] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(TEST-1) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:37,504] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:37,516] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:109)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:110)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:211)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:301)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:135)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:118)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-09-08 03:02:37,516] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:37,538] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:37,712] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(TEST-0) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:37,717] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(TEST-0 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:37,868] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition TEST-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:37,869] INFO [Log partition=TEST-0, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:37,984] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment HashMap(0 -> ArrayBuffer(2, 1, 0), 1 -> ArrayBuffer(0, 2, 1), 2 -> ArrayBuffer(1, 0, 2), 3 -> ArrayBuffer(2, 0, 1), 4 -> ArrayBuffer(0, 1, 2), 5 -> ArrayBuffer(1, 2, 0), 6 -> ArrayBuffer(2, 1, 0), 7 -> ArrayBuffer(0, 2, 1), 8 -> ArrayBuffer(1, 0, 2), 9 -> ArrayBuffer(2, 0, 1), 10 -> ArrayBuffer(0, 1, 2), 11 -> ArrayBuffer(1, 2, 0), 12 -> ArrayBuffer(2, 1, 0), 13 -> ArrayBuffer(0, 2, 1), 14 -> ArrayBuffer(1, 0, 2), 15 -> ArrayBuffer(2, 0, 1), 16 -> ArrayBuffer(0, 1, 2), 17 -> ArrayBuffer(1, 2, 0), 18 -> ArrayBuffer(2, 1, 0), 19 -> ArrayBuffer(0, 2, 1), 20 -> ArrayBuffer(1, 0, 2), 21 -> ArrayBuffer(2, 0, 1), 22 -> ArrayBuffer(0, 1, 2), 23 -> ArrayBuffer(1, 2, 0), 24 -> ArrayBuffer(2, 1, 0), 25 -> ArrayBuffer(0, 2, 1), 26 -> ArrayBuffer(1, 0, 2), 27 -> ArrayBuffer(2, 0, 1), 28 -> ArrayBuffer(0, 1, 2), 29 -> ArrayBuffer(1, 2, 0), 30 -> ArrayBuffer(2, 1, 0), 31 -> ArrayBuffer(0, 2, 1), 32 -> ArrayBuffer(1, 0, 2), 33 -> ArrayBuffer(2, 0, 1), 34 -> ArrayBuffer(0, 1, 2), 35 -> ArrayBuffer(1, 2, 0), 36 -> ArrayBuffer(2, 1, 0), 37 -> ArrayBuffer(0, 2, 1), 38 -> ArrayBuffer(1, 0, 2), 39 -> ArrayBuffer(2, 0, 1), 40 -> ArrayBuffer(0, 1, 2), 41 -> ArrayBuffer(1, 2, 0), 42 -> ArrayBuffer(2, 1, 0), 43 -> ArrayBuffer(0, 2, 1), 44 -> ArrayBuffer(1, 0, 2), 45 -> ArrayBuffer(2, 0, 1), 46 -> ArrayBuffer(0, 1, 2), 47 -> ArrayBuffer(1, 2, 0), 48 -> ArrayBuffer(2, 1, 0), 49 -> ArrayBuffer(0, 2, 1)) (kafka.zk.AdminZkClient)
[2022-09-08 03:02:38,052] INFO [KafkaApi-1] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 3 is successful (kafka.server.KafkaApis)
[2022-09-08 03:02:38,846] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-11, __consumer_offsets-12, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:38,858] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,859] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,860] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2022-09-08 03:02:38,860] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,879] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,881] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,881] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2022-09-08 03:02:38,882] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,901] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,909] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,909] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2022-09-08 03:02:38,909] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,926] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,934] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,934] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2022-09-08 03:02:38,934] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,943] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,948] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,948] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2022-09-08 03:02:38,948] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,960] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:38,961] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:38,961] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2022-09-08 03:02:38,961] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:38,993] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,002] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,002] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2022-09-08 03:02:39,002] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,020] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,022] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,022] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2022-09-08 03:02:39,022] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,040] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,042] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,042] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2022-09-08 03:02:39,042] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,057] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,063] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,064] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2022-09-08 03:02:39,064] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,084] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,085] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,085] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2022-09-08 03:02:39,085] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,098] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,099] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,099] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2022-09-08 03:02:39,099] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,121] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,123] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,123] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,123] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,145] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,161] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,161] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2022-09-08 03:02:39,162] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,215] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,229] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,229] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2022-09-08 03:02:39,229] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,258] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,260] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,260] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2022-09-08 03:02:39,260] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,306] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,323] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,323] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2022-09-08 03:02:39,323] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,335] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,337] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,337] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2022-09-08 03:02:39,337] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,382] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,387] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,387] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2022-09-08 03:02:39,388] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,409] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,432] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,432] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2022-09-08 03:02:39,432] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,460] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,461] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,473] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2022-09-08 03:02:39,473] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,489] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,499] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,499] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2022-09-08 03:02:39,499] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,521] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,522] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,522] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2022-09-08 03:02:39,522] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,536] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,537] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,537] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2022-09-08 03:02:39,537] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,551] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,552] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,552] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2022-09-08 03:02:39,552] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,561] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,562] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,562] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2022-09-08 03:02:39,562] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,569] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,584] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,584] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2022-09-08 03:02:39,584] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,621] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,634] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,634] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2022-09-08 03:02:39,635] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,686] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,691] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,692] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2022-09-08 03:02:39,692] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,707] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,709] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,709] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2022-09-08 03:02:39,709] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,716] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,717] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,717] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2022-09-08 03:02:39,717] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,730] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,737] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,737] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2022-09-08 03:02:39,737] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,768] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,769] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,776] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2022-09-08 03:02:39,776] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,798] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,799] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,799] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2022-09-08 03:02:39,799] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,804] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,805] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,805] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2022-09-08 03:02:39,805] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,825] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,826] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,826] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2022-09-08 03:02:39,827] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,844] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,845] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,845] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2022-09-08 03:02:39,851] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,875] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,876] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,876] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2022-09-08 03:02:39,876] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,889] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,890] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,890] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2022-09-08 03:02:39,890] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,902] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,903] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,903] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2022-09-08 03:02:39,903] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,912] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,912] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,913] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2022-09-08 03:02:39,913] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,922] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,927] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,927] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2022-09-08 03:02:39,927] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,939] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,940] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,940] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2022-09-08 03:02:39,940] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,960] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,961] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,961] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2022-09-08 03:02:39,961] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,976] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,977] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,977] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2022-09-08 03:02:39,977] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:39,987] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:39,989] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:39,989] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2022-09-08 03:02:39,989] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:40,008] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:40,013] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:40,013] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2022-09-08 03:02:40,018] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:40,045] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:40,078] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:40,078] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2022-09-08 03:02:40,078] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:40,094] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:40,108] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:40,108] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2022-09-08 03:02:40,108] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:40,116] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka_2.13-2.7.1/logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2022-09-08 03:02:40,124] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka_2.13-2.7.1/logs/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.7-IV2, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2022-09-08 03:02:40,124] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2022-09-08 03:02:40,124] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-09-08 03:02:40,125] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-15, __consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-21, __consumer_offsets-19, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-25, __consumer_offsets-39, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:40,127] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions HashMap(__consumer_offsets-22 -> (offset=0, leaderEpoch=0), __consumer_offsets-25 -> (offset=0, leaderEpoch=0), __consumer_offsets-31 -> (offset=0, leaderEpoch=0), __consumer_offsets-3 -> (offset=0, leaderEpoch=0), __consumer_offsets-37 -> (offset=0, leaderEpoch=0), __consumer_offsets-15 -> (offset=0, leaderEpoch=0), __consumer_offsets-19 -> (offset=0, leaderEpoch=0), __consumer_offsets-13 -> (offset=0, leaderEpoch=0), __consumer_offsets-43 -> (offset=0, leaderEpoch=0), __consumer_offsets-39 -> (offset=0, leaderEpoch=0), __consumer_offsets-34 -> (offset=0, leaderEpoch=0), __consumer_offsets-21 -> (offset=0, leaderEpoch=0), __consumer_offsets-4 -> (offset=0, leaderEpoch=0), __consumer_offsets-27 -> (offset=0, leaderEpoch=0), __consumer_offsets-7 -> (offset=0, leaderEpoch=0), __consumer_offsets-9 -> (offset=0, leaderEpoch=0), __consumer_offsets-46 -> (offset=0, leaderEpoch=0), __consumer_offsets-33 -> (offset=0, leaderEpoch=0), __consumer_offsets-49 -> (offset=0, leaderEpoch=0), __consumer_offsets-16 -> (offset=0, leaderEpoch=0), __consumer_offsets-28 -> (offset=0, leaderEpoch=0), __consumer_offsets-45 -> (offset=0, leaderEpoch=0), __consumer_offsets-1 -> (offset=0, leaderEpoch=0), __consumer_offsets-10 -> (offset=0, leaderEpoch=0), __consumer_offsets-40 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:40,144] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,161] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,162] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,161] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 17 milliseconds, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,168] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,168] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,168] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 7 milliseconds, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 7 milliseconds, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,184] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,184] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,184] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,185] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,186] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,187] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,188] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,189] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,190] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,194] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,194] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,194] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,194] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,195] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-3. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-37. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-22. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-10. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-33. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-19. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-34. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,196] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-4. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-45. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-15. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-49. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-39. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-27. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-31. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-46. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-16. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-40. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-43. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-13. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,197] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-28. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:40,269] ERROR [KafkaApi-1] Number of alive brokers '2' does not meet the required replication factor '3' for the offsets topic (configured via 'offsets.topic.replication.factor'). This error can be ignored if the cluster is starting up and not all brokers are up yet. (kafka.server.KafkaApis)
[2022-09-08 03:02:40,512] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-15 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,513] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,513] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-13 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,513] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,513] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-46 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,514] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,514] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,514] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,514] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-21 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,514] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,515] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-19 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,515] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,515] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-28 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,515] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,515] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,515] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,515] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-40 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,518] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,519] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,519] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,519] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,519] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,519] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-34 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,519] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,520] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-16 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,520] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,520] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-45 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,520] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,520] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-43 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,520] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,521] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-10 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,521] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,521] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-22 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,521] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,521] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-49 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,521] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,521] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-31 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,521] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,521] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-27 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-25 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-39 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-37 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-4 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:40,522] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-33 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:40,522] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:51,021] INFO [broker-1-to-controller-send-thread]: Recorded new controller, from now on will use broker 0 (kafka.server.BrokerToControllerRequestThread)
[2022-09-08 03:02:51,263] INFO [Partition __consumer_offsets-48 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,263] INFO [Partition __consumer_offsets-11 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,263] INFO [Partition __consumer_offsets-44 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,263] INFO [Partition __consumer_offsets-42 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,263] INFO [Partition __consumer_offsets-23 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-17 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-32 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-30 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-26 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-5 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-38 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-36 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-47 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-14 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-12 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-41 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-24 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-20 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-18 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,264] INFO [Partition __consumer_offsets-0 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,265] INFO [Partition __consumer_offsets-29 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,265] INFO [Partition __consumer_offsets-8 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,265] INFO [Partition __consumer_offsets-6 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,265] INFO [Partition __consumer_offsets-35 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,265] INFO [Partition __consumer_offsets-2 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [1] (kafka.cluster.Partition)
[2022-09-08 03:02:51,326] INFO [Partition TEST-1 broker=1] ISR updated from AlterIsr to 1,0,2 and version updated to [2] (kafka.cluster.Partition)
[2022-09-08 03:02:58,118] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:58,145] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-15, __consumer_offsets-13, __consumer_offsets-45, __consumer_offsets-43, __consumer_offsets-9, __consumer_offsets-21, __consumer_offsets-19, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-27, TEST-0, __consumer_offsets-25, __consumer_offsets-39, __consumer_offsets-7, __consumer_offsets-37, __consumer_offsets-3, __consumer_offsets-33, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:58,182] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(__consumer_offsets-25 -> (offset=0, leaderEpoch=1), __consumer_offsets-31 -> (offset=0, leaderEpoch=1), __consumer_offsets-3 -> (offset=0, leaderEpoch=1), __consumer_offsets-37 -> (offset=0, leaderEpoch=1), __consumer_offsets-15 -> (offset=0, leaderEpoch=1), __consumer_offsets-19 -> (offset=4, leaderEpoch=1), __consumer_offsets-13 -> (offset=0, leaderEpoch=1), __consumer_offsets-43 -> (offset=0, leaderEpoch=1), __consumer_offsets-39 -> (offset=0, leaderEpoch=1), __consumer_offsets-21 -> (offset=0, leaderEpoch=1), TEST-0 -> (offset=10, leaderEpoch=2), __consumer_offsets-27 -> (offset=0, leaderEpoch=1), __consumer_offsets-7 -> (offset=0, leaderEpoch=1), __consumer_offsets-9 -> (offset=0, leaderEpoch=1), __consumer_offsets-33 -> (offset=0, leaderEpoch=1), __consumer_offsets-49 -> (offset=0, leaderEpoch=1), __consumer_offsets-45 -> (offset=0, leaderEpoch=1), __consumer_offsets-1 -> (offset=0, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:02:58,184] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,188] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,199] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,188] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,272] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,273] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,274] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-34 in 2 milliseconds, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-4 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-40 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-10 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,275] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-28 in 2 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-46 in 3 milliseconds, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-16 in 3 milliseconds, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-3. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-37. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-7. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-39. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-9. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-27. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-31. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-1. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,276] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-33. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,306] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-19. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,306] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-21. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,306] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-25. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,313] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-43. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,313] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-13. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,313] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-45. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,313] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-15. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,313] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-49. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:02:58,337] INFO [Log partition=TEST-0, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 10 has no effect as the largest offset in the log is 9 (kafka.log.Log)
[2022-09-08 03:02:58,337] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 4 has no effect as the largest offset in the log is 3 (kafka.log.Log)
[2022-09-08 03:02:58,362] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-15 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,362] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,362] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-13 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,362] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,362] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-45 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,362] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,363] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-43 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,363] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,363] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-9 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,363] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,363] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-21 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,363] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,363] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-49 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,363] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,368] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-31 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,368] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,368] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-27 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,368] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,368] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-25 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,368] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,369] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-39 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,369] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,369] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-7 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,369] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,369] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-37 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,369] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,370] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-3 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,370] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,370] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-33 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,394] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,394] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition __consumer_offsets-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-09-08 03:02:58,394] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:02:58,478] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-11, __consumer_offsets-12, __consumer_offsets-29, __consumer_offsets-32, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, TEST-1, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:03:05,217] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-0, __consumer_offsets-48, __consumer_offsets-30, __consumer_offsets-12, TEST-1, __consumer_offsets-42, __consumer_offsets-24, __consumer_offsets-6, __consumer_offsets-36, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:03:05,243] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions HashMap(__consumer_offsets-30 -> (offset=0, leaderEpoch=2), __consumer_offsets-36 -> (offset=0, leaderEpoch=2), __consumer_offsets-24 -> (offset=0, leaderEpoch=2), __consumer_offsets-48 -> (offset=0, leaderEpoch=2), __consumer_offsets-6 -> (offset=0, leaderEpoch=2), __consumer_offsets-12 -> (offset=0, leaderEpoch=2), __consumer_offsets-42 -> (offset=0, leaderEpoch=2), __consumer_offsets-18 -> (offset=0, leaderEpoch=2), __consumer_offsets-0 -> (offset=0, leaderEpoch=2), TEST-1 -> (offset=14, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2022-09-08 03:03:05,245] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,245] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-18. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,245] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-36. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-6. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-24. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,268] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-42. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-12. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-30. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-0. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,269] INFO [GroupMetadataManager brokerId=1] Finished unloading __consumer_offsets-48. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2022-09-08 03:03:05,280] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,281] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,282] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,283] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,283] INFO [Log partition=TEST-1, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 14 has no effect as the largest offset in the log is 13 (kafka.log.Log)
[2022-09-08 03:03:05,283] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,284] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,284] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,285] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:05,291] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka_2.13-2.7.1/logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2022-09-08 03:03:18,004] INFO Unable to read additional data from server sessionid 0x100003c3ee30000, likely server has closed socket, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2022-09-08 03:03:18,032] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1437983948, epoch=43) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:110)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:211)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:301)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:135)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:118)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-09-08 03:03:18,040] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1437983948, epoch=43), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 2 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:110)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:211)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:301)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:135)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:118)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
