11:02:08.925 [main] INFO io.redit.samples.kafka13563.SampleTest - wait for zookeeper...
11:02:08.925 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 startZookeeper...
11:02:08.931 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 startZookeeper...
11:02:08.931 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 startZookeeper...
11:02:18.932 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 checkStatus...
11:02:19.237 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
11:02:19.238 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower

11:02:20.239 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 checkStatus...
11:02:20.542 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
11:02:20.542 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: follower

11:02:21.543 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 checkStatus...
11:02:21.887 [main] INFO io.redit.samples.kafka13563.SampleTest - server3: cd /zookeeper/apache-zookeeper-3.7.1-bin && bin/zkServer.sh status
11:02:21.887 [main] INFO io.redit.samples.kafka13563.SampleTest - Client port found: 2181. Client address: localhost. Client SSL: false.
Mode: leader

11:02:22.888 [main] INFO io.redit.samples.kafka13563.SampleTest - wait for kafka...
11:02:22.888 [main] INFO io.redit.samples.kafka13563.SampleTest - server1 startKafka...
11:02:22.889 [main] INFO io.redit.samples.kafka13563.SampleTest - server2 startKafka...
11:02:22.889 [main] INFO io.redit.samples.kafka13563.SampleTest - server3 startKafka...
11:02:33.153 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: jps
11:02:33.153 [main] INFO io.redit.samples.kafka13563.SampleTest - 564 Jps
37 QuorumPeerMain
477 Kafka

11:02:33.407 [main] INFO io.redit.samples.kafka13563.SampleTest - server2: jps
11:02:33.407 [main] INFO io.redit.samples.kafka13563.SampleTest - 562 Jps
34 QuorumPeerMain
476 Kafka

11:02:33.682 [main] INFO io.redit.samples.kafka13563.SampleTest - server3: jps
11:02:33.682 [main] INFO io.redit.samples.kafka13563.SampleTest - 482 Kafka
36 QuorumPeerMain
568 Jps

11:02:36.780 [main] INFO io.redit.samples.kafka13563.SampleTest - server1: cd /kafka/kafka_2.13-2.7.1 && bin/kafka-topics.sh --bootstrap-server 10.5.0.4:9092,10.5.0.3:9092,10.5.0.2:9092 --create --replication-factor 3 --partitions 2 --topic TEST
11:02:36.780 [main] INFO io.redit.samples.kafka13563.SampleTest - Created topic TEST.

11:02:36.817 [main] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values:
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [10.5.0.4:9092, 10.5.0.3:9092, 10.5.0.2:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-TestGroup-1
	client.rack =
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = TestGroup
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.VoidDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

11:02:36.819 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initializing the Kafka consumer
11:02:37.130 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
11:02:37.130 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
11:02:37.130 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1662606157129
11:02:37.132 [main] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Kafka consumer initialized
11:02:37.132 [main] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Subscribed to partition(s): TEST-0
11:02:37.147 [main] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values:
	acks = -1
	batch.size = 16384
	bootstrap.servers = [10.5.0.4:9092, 10.5.0.3:9092, 10.5.0.2:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.VoidSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 127000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

11:02:37.152 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initialize connection to node 10.5.0.3:9092 (id: -2 rack: null) for sending metadata request
11:02:37.153 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.3:9092 (id: -2 rack: null) using address /10.5.0.3
11:02:37.165 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
11:02:37.169 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -2
11:02:37.184 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Overriding the default acks to all since idempotence is enabled.
11:02:37.190 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.7.1
11:02:37.190 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 61dbce85d0d41457
11:02:37.190 [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1662606157190
11:02:37.190 [main] DEBUG org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer started
11:02:37.198 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Starting Kafka producer I/O thread.
11:02:37.199 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Transition from state UNINITIALIZED to INITIALIZING
============ kafkacat :[kafkacat -b 10.5.0.4:9092 -L]==============
Metadata for all topics (from broker 0: 10.5.0.4:9092/0):
 3 brokers:
  broker 0 at 10.5.0.4:9092
  broker 2 at 10.5.0.2:9092 (controller)
  broker 1 at 10.5.0.3:9092
 1 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 0, replicas: 0,2,1, isrs: 0,2,1
    partition 1, leader 2, replicas: 2,1,0, isrs: 2,1,0
kafkaControllerId: 2
11:02:37.237 [main] INFO io.redit.samples.kafka13563.SampleTest - ============ shutdown kafka service on server 3 ============
11:02:37.522 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Enqueuing transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1)
11:02:37.524 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 10.5.0.2:9092 (id: -3 rack: null) for sending metadata request
11:02:37.524 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.2:9092 (id: -3 rack: null) using address /10.5.0.2
11:02:37.526 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -3
11:02:37.527 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -3. Fetching API versions.
11:02:37.527 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -3.
11:02:37.531 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node -2. Fetching API versions.
11:02:37.535 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node -2.
11:02:37.544 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=0) and timeout 30000 to node -2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:37.556 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0) and timeout 30000 to node -3: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:37.556 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.3:9092 (id: -2 rack: null) using address /10.5.0.3
11:02:37.557 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node -2
11:02:37.557 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node -2. Fetching API versions.
11:02:37.557 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node -2.
11:02:37.557 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1) and timeout 30000 to node -2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:37.666 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node -2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=0): org.apache.kafka.common.requests.ApiVersionsResponse@66349255
11:02:37.668 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node -2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:37.670 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: -2 rack: null)
11:02:37.670 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=1) and timeout 30000 to node -2: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:37.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -3 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=0): org.apache.kafka.common.requests.ApiVersionsResponse@758b20c0
11:02:37.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node -3: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:37.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.2:9092 (id: -3 rack: null)
11:02:37.673 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=2) and timeout 30000 to node -3: {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:37.674 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node -2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=1): org.apache.kafka.common.requests.ApiVersionsResponse@4c5e65bd
11:02:37.675 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node -2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:37.687 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Sending transactional request InitProducerIdRequestData(transactionalId=null, transactionTimeoutMs=2147483647, producerId=-1, producerEpoch=-1) to node 10.5.0.3:9092 (id: -2 rack: null) with correlation ID 3
11:02:37.687 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending INIT_PRODUCER_ID request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=4, clientId=producer-1, correlationId=3) and timeout 30000 to node -2: {transactional_id=null,transaction_timeout_ms=2147483647,producer_id=-1,producer_epoch=-1,_tagged_fields={}}
11:02:37.689 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node -3 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=2): org.apache.kafka.common.requests.MetadataResponse@4c1ee46f
11:02:37.697 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: -xzXV6INQZuCQMvamkAusg
11:02:37.697 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:37.737 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received INIT_PRODUCER_ID response from node -2 for request with header RequestHeader(apiKey=INIT_PRODUCER_ID, apiVersion=4, clientId=producer-1, correlationId=3): InitProducerIdResponseData(throttleTimeMs=0, errorCode=0, producerId=0, producerEpoch=0)
11:02:37.738 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 0 with epoch 0
11:02:37.738 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] Transition from state INITIALIZING to READY
11:02:37.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node -2 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=1): org.apache.kafka.common.requests.MetadataResponse@6264d31a
11:02:37.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from null to epoch 0 from new metadata
11:02:37.754 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from null to epoch 1 from new metadata
11:02:37.761 [pool-6-thread-1] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Cluster ID: -xzXV6INQZuCQMvamkAusg
11:02:37.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 2 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[0], replicas=0,2,1, isr=0,2,1, offlineReplicas=), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:37.768 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.2 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:325)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
11:02:37.770 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node -3 disconnected.
11:02:37.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.2:9092 (id: 2 rack: null)
11:02:37.779 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
11:02:37.782 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.2 disconnected
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:219)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:245)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.fetchCommittedOffsets(ConsumerCoordinator.java:848)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.refreshCommittedOffsetsIfNeeded(ConsumerCoordinator.java:800)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateFetchPositions(KafkaConsumer.java:2415)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1261)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1226)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:141)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
11:02:37.782 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 disconnected.
11:02:37.782 [pool-6-thread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection to node 2 (/10.5.0.2:9092) could not be established. Broker may not be available.
11:02:37.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=2) due to node 2 being disconnected
11:02:37.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] FindCoordinator request failed due to {}
org.apache.kafka.common.errors.DisconnectException: null
11:02:37.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.DisconnectException: null
11:02:37.789 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 10.5.0.2:9092 (id: 2 rack: null) for sending metadata request
11:02:37.789 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
11:02:37.790 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.2 disconnected
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:219)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:325)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
11:02:37.790 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 2 disconnected.
11:02:37.790 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Connection to node 2 (/10.5.0.2:9092) could not be established. Broker may not be available.
11:02:37.852 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initialize connection to node 10.5.0.3:9092 (id: 1 rack: null) for sending metadata request
11:02:37.852 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.3:9092 (id: 1 rack: null) using address /10.5.0.3
11:02:37.854 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
11:02:37.854 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 1. Fetching API versions.
11:02:37.854 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 1.
11:02:37.854 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=3) and timeout 30000 to node 1: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:37.875 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=3): org.apache.kafka.common.requests.ApiVersionsResponse@7577956a
11:02:37.876 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 1: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:37.882 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:37.882 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=4) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:37.885 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=4): org.apache.kafka.common.requests.MetadataResponse@65bba547
11:02:37.885 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 0 to epoch 1 from new metadata
11:02:37.885 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:37.886 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 3 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:37.886 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:37.886 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:37.890 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initialize connection to node 10.5.0.4:9092 (id: 0 rack: null) for sending metadata request
11:02:37.890 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.4:9092 (id: 0 rack: null) using address /10.5.0.4
11:02:37.891 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
11:02:37.891 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 0. Fetching API versions.
11:02:37.891 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 0.
11:02:37.891 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=4) and timeout 30000 to node 0: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:37.900 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 0 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=4): org.apache.kafka.common.requests.ApiVersionsResponse@2d2b8089
11:02:37.901 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node 0: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:37.901 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:37.901 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=5) and timeout 30000 to node 0: {topics=[],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:37.904 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 0 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=5): org.apache.kafka.common.requests.MetadataResponse@8aed2e6
11:02:37.905 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 3 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.061 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.062 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158061, latencyMs=175, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=5), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.062 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.062 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.062 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.062 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=6) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=6): org.apache.kafka.common.requests.MetadataResponse@51b4b3a5
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 4 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.065 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.095 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.099 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158095, latencyMs=30, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=7), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.099 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.099 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.157 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.165 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.165 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=9) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.176 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.177 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158176, latencyMs=20, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=8), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.177 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.177 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=9): org.apache.kafka.common.requests.MetadataResponse@250e9882
11:02:38.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.181 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 5 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.181 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.181 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.194 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:38.194 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=6) and timeout 30000 to node 0: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.199 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 0 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=6): org.apache.kafka.common.requests.MetadataResponse@25a6cfdf
11:02:38.200 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-0 from null to epoch 1 from new metadata
11:02:38.200 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-1 from null to epoch 1 from new metadata
11:02:38.206 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 4 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.222 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.223 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158222, latencyMs=41, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=10), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.223 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.223 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.226 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.3:9092 (id: 1 rack: null) using address /10.5.0.3
11:02:38.227 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 1
11:02:38.228 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 1. Fetching API versions.
11:02:38.228 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 1.
11:02:38.228 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=7) and timeout 30000 to node 1: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:38.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 1 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=7): org.apache.kafka.common.requests.ApiVersionsResponse@59a60d8c
11:02:38.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node 1: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:38.238 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId of partition TEST-1 set to 0 with epoch 0. Reinitialize sequence at beginning.
11:02:38.238 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 0 being sent to partition TEST-1
11:02:38.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=8) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:38.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=11) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=11): org.apache.kafka.common.requests.MetadataResponse@3819ff7b
11:02:38.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 6 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.303 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.303 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.394 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.394 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158394, latencyMs=91, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=12), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.394 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.394 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.401 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.401 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=13) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.410 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=13): org.apache.kafka.common.requests.MetadataResponse@5b8aefc7
11:02:38.410 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.410 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.411 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 7 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.411 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.411 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.459 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.460 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158459, latencyMs=48, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=14), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.460 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.460 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.510 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.511 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=15) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.525 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=15): org.apache.kafka.common.requests.MetadataResponse@78fb5259
11:02:38.525 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.525 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.526 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 8 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.526 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.526 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.655 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.655 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158655, latencyMs=129, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=16), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.655 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.655 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.655 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.656 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=17) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.662 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=17): org.apache.kafka.common.requests.MetadataResponse@29601f4c
11:02:38.662 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.662 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.663 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 9 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.663 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.663 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.689 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.689 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158689, latencyMs=26, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=18), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.689 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.689 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.726 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=8): org.apache.kafka.common.requests.ProduceResponse@2ba85adc
11:02:38.726 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 0
11:02:38.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=19) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.768 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=19): org.apache.kafka.common.requests.MetadataResponse@5ef5df3c
11:02:38.768 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.768 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.768 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 10 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.768 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.769 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.806 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158806, latencyMs=38, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=20), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.869 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.869 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=21) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.871 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=21): org.apache.kafka.common.requests.MetadataResponse@520df7f2
11:02:38.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 11 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.872 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:38.902 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:38.903 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606158902, latencyMs=30, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=22), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:38.903 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:38.903 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:38.971 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.972 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=23) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:38.974 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=23): org.apache.kafka.common.requests.MetadataResponse@70c60e70
11:02:38.974 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:38.974 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:38.975 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 12 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:38.975 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:38.975 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.026 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.026 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159026, latencyMs=51, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=24), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.026 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.026 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.074 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=25) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.080 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=25): org.apache.kafka.common.requests.MetadataResponse@2989dd76
11:02:39.080 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.080 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.080 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 13 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.081 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.081 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.100 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.101 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159100, latencyMs=19, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=26), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.101 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.101 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.150 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.181 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.181 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=28) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.184 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.184 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159184, latencyMs=34, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=27), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.184 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.185 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.185 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=28): org.apache.kafka.common.requests.MetadataResponse@14060dd2
11:02:39.185 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.185 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.186 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 14 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.186 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.186 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.226 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId of partition TEST-0 set to 0 with epoch 0. Reinitialize sequence at beginning.
11:02:39.226 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 0 being sent to partition TEST-0
11:02:39.227 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=9) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:39.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159266, latencyMs=80, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=29), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.286 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.286 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=30) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.291 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=30): org.apache.kafka.common.requests.MetadataResponse@547334ac
11:02:39.291 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.291 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.292 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 15 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.292 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.292 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.333 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.333 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159333, latencyMs=41, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=31), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.333 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.333 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.395 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.395 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=32) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.402 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=32): org.apache.kafka.common.requests.MetadataResponse@22dadc54
11:02:39.403 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.403 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.403 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 16 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.403 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.403 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.440 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.441 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159440, latencyMs=37, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=33), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.441 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.441 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.488 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=9): org.apache.kafka.common.requests.ProduceResponse@83fa9ef
11:02:39.488 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 0
11:02:39.503 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.503 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=34) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=34): org.apache.kafka.common.requests.MetadataResponse@45dfc714
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 17 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.507 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.529 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159529, latencyMs=22, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=35), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.607 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.607 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=36) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.622 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=36): org.apache.kafka.common.requests.MetadataResponse@61932ae0
11:02:39.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 18 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.623 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.652 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.652 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159652, latencyMs=29, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=37), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.652 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.652 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.723 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.723 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=38) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.730 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=38): org.apache.kafka.common.requests.MetadataResponse@2c08b42a
11:02:39.731 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.731 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.731 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 19 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.731 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.731 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159762, latencyMs=31, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=39), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.831 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=40) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.833 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=40): org.apache.kafka.common.requests.MetadataResponse@5844e583
11:02:39.834 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.834 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.834 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 20 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.834 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.834 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.862 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.862 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159862, latencyMs=28, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=41), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.862 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.862 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:39.934 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.934 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=42) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:39.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=42): org.apache.kafka.common.requests.MetadataResponse@63987ef8
11:02:39.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:39.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:39.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 21 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:39.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:39.943 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:39.972 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:39.972 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606159972, latencyMs=29, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=43), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:39.972 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:39.972 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:40.043 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.043 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=44) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:40.049 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=44): org.apache.kafka.common.requests.MetadataResponse@1b248c41
11:02:40.049 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:40.049 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:40.050 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 22 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:40.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.051 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:40.063 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:40.064 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606160063, latencyMs=12, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=45), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:40.064 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:40.064 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:40.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.149 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=46) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:40.150 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.150 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=47) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:40.158 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=46): org.apache.kafka.common.requests.MetadataResponse@7264d2eb
11:02:40.158 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:40.158 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:40.158 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 23 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.2:9092 (id: 2 rack: null)}
11:02:40.175 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=47): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:40.175 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606160175, latencyMs=25, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=47), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:40.175 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:40.175 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:40.227 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 1 being sent to partition TEST-1
11:02:40.227 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=10) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:40.236 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=10): org.apache.kafka.common.requests.ProduceResponse@148742ee
11:02:40.236 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 1
11:02:40.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=48) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:40.263 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=48): org.apache.kafka.common.requests.MetadataResponse@df349d9
11:02:40.263 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:40.263 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:40.263 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 24 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:40.264 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.264 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=49) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:40.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=49): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1)
11:02:40.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606160278, latencyMs=14, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=49), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=15, errorMessage='The coordinator is not available.', nodeId=-1, host='', port=-1))
11:02:40.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator lookup failed: The coordinator is not available.
11:02:40.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Coordinator discovery failed, refreshing metadata
org.apache.kafka.common.errors.CoordinatorNotAvailableException: The coordinator is not available.
11:02:40.363 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.364 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=50) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=50): org.apache.kafka.common.requests.MetadataResponse@2dbc8921
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 25 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1, offlineReplicas=2), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0, offlineReplicas=2)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:02:40.366 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=51) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:02:40.373 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=51): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092)
11:02:40.373 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606160373, latencyMs=7, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=51), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=0, host='10.5.0.4', port=9092))
11:02:40.373 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null)
11:02:40.373 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 2147483647 rack: null) using address /10.5.0.4
11:02:40.374 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetching committed offsets for partitions: [TEST-0]
11:02:40.382 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483647
11:02:40.383 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2147483647. Fetching API versions.
11:02:40.383 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2147483647.
11:02:40.383 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=53) and timeout 30000 to node 2147483647: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:40.387 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2147483647 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=53): org.apache.kafka.common.requests.ApiVersionsResponse@256b2b58
11:02:40.387 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2147483647: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:40.388 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_FETCH request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=52) and timeout 30000 to node 2147483647: {group_id=TestGroup,topics=[{name=TEST,partition_indexes=[0],_tagged_fields={}}],require_stable=true,_tagged_fields={}}
11:02:40.394 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_FETCH response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_FETCH, apiVersion=7, clientId=consumer-TestGroup-1, correlationId=52): org.apache.kafka.common.requests.OffsetFetchResponse@6275c89a
11:02:40.395 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Found no committed offset for partition TEST-0
11:02:40.402 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending ListOffsetRequest ListOffsetRequestData(replicaId=-1, isolationLevel=0, topics=[ListOffsetTopic(name='TEST', partitions=[ListOffsetPartition(partitionIndex=0, currentLeaderEpoch=1, timestamp=-1, maxNumOffsets=1)])]) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:40.402 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 0 rack: null) using address /10.5.0.4
11:02:40.404 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 0
11:02:40.404 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 0. Fetching API versions.
11:02:40.404 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 0.
11:02:40.404 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=55) and timeout 30000 to node 0: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:40.407 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 0 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=55): org.apache.kafka.common.requests.ApiVersionsResponse@1a6328e7
11:02:40.408 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 0: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:40.408 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending LIST_OFFSETS request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=5, clientId=consumer-TestGroup-1, correlationId=54) and timeout 30000 to node 0: {replica_id=-1,isolation_level=0,topics=[{name=TEST,partitions=[{partition_index=0,current_leader_epoch=1,timestamp=-1}]}]}
11:02:40.414 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received LIST_OFFSETS response from node 0 for request with header RequestHeader(apiKey=LIST_OFFSETS, apiVersion=5, clientId=consumer-TestGroup-1, correlationId=54): ListOffsetResponseData(throttleTimeMs=0, topics=[ListOffsetTopicResponse(name='TEST', partitions=[ListOffsetPartitionResponse(partitionIndex=0, errorCode=0, oldStyleOffsets=[], timestamp=-1, offset=1, leaderEpoch=1)])])
11:02:40.415 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Handling ListOffsetResponse response for TEST-0. Fetched offset 1, timestamp -1
11:02:40.416 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Not replacing existing epoch 1 with new epoch 1 for partition TEST-0
11:02:40.417 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Resetting offset for partition TEST-0 to position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}}.
11:02:40.419 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:40.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
11:02:40.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED FullFetchRequest(TEST-0) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:40.423 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=56) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=0,session_epoch=0,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=1,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:40.935 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=56): org.apache.kafka.common.requests.FetchResponse@2800419a
11:02:40.935 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent a full fetch response that created a new incremental fetch session 880843346 with 1 response partition(s)
11:02:40.937 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 1 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=1, lastStableOffset = 1, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:40.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:40.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=1) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:40.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:40.942 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=57) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=1,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:41.229 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 1 being sent to partition TEST-0
11:02:41.229 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=11) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:41.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=57): org.apache.kafka.common.requests.FetchResponse@537cffde
11:02:41.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:41.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 1 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=2, lastStableOffset = 2, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:41.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=11): org.apache.kafka.common.requests.ProduceResponse@43703748
11:02:41.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 1
11:02:41.247 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:41.247 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=2) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:41.247 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:41.247 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=58) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=2,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=2,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 1, CreateTime = 1662606161228, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:41.228Z)============
11:02:41.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=58): org.apache.kafka.common.requests.FetchResponse@339e5651
11:02:41.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:41.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:41.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=3) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:41.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:41.754 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=59) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=3,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:42.125 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=2, leaderEpoch=1, metadata=''}}
11:02:42.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=60) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=2,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:02:42.187 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=60): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:02:42.187 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 2 for partition TEST-0
11:02:42.187 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=2, leaderEpoch=1, metadata=''}}
11:02:42.229 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 2 being sent to partition TEST-1
11:02:42.230 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=12) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:42.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=59): org.apache.kafka.common.requests.FetchResponse@59d83488
11:02:42.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:42.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:42.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=4) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:42.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:42.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=61) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=4,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:42.266 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=12): org.apache.kafka.common.requests.ProduceResponse@43c9e8f4
11:02:42.266 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 2
11:02:42.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=61): org.apache.kafka.common.requests.FetchResponse@707e5e72
11:02:42.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:42.764 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=2, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:42.764 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=5) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:42.764 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:42.764 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=62) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=5,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:43.230 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 2 being sent to partition TEST-0
11:02:43.230 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=13) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:43.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=62): org.apache.kafka.common.requests.FetchResponse@55b10b2e
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 2 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=3, lastStableOffset = 3, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=6) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:43.246 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=63) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=6,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=3,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 2, CreateTime = 1662606163230, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:43.229Z)============
11:02:43.250 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=13): org.apache.kafka.common.requests.ProduceResponse@364c41b3
11:02:43.250 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 2
11:02:43.756 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=63): org.apache.kafka.common.requests.FetchResponse@75e58695
11:02:43.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:43.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:43.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=7) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:43.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:43.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=64) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=7,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:44.231 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 3 being sent to partition TEST-1
11:02:44.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=14) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:44.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=14): org.apache.kafka.common.requests.ProduceResponse@1872f5a6
11:02:44.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 3
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=64): org.apache.kafka.common.requests.FetchResponse@6d0180d5
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=8) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:44.262 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=65) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=8,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:44.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=65): org.apache.kafka.common.requests.FetchResponse@6f0edec9
11:02:44.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:44.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=3, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:44.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=9) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:44.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:44.767 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=66) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=9,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:45.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 3 being sent to partition TEST-0
11:02:45.232 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=15) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:45.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=66): org.apache.kafka.common.requests.FetchResponse@32bb407d
11:02:45.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:45.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 3 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=4, lastStableOffset = 4, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:45.243 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:45.243 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=10) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:45.243 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:45.243 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=67) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=10,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=4,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 3, CreateTime = 1662606165232, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:45.232Z)============
11:02:45.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=15): org.apache.kafka.common.requests.ProduceResponse@5afa4b97
11:02:45.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 3
11:02:45.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=67): org.apache.kafka.common.requests.FetchResponse@6b33b991
11:02:45.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:45.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:45.752 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=11) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:45.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:45.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=68) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=11,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:46.233 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 4 being sent to partition TEST-1
11:02:46.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=16) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:46.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=16): org.apache.kafka.common.requests.ProduceResponse@56788674
11:02:46.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 4
11:02:46.254 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=68): org.apache.kafka.common.requests.FetchResponse@ad59b0a
11:02:46.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:46.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:46.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=12) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:46.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:46.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=69) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=12,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:46.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=69): org.apache.kafka.common.requests.FetchResponse@1334e40f
11:02:46.760 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:46.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=4, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:46.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=13) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:46.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:46.761 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=70) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=13,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:47.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=4, leaderEpoch=1, metadata=''}}
11:02:47.126 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=71) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=4,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:02:47.137 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=71): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:02:47.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 4 for partition TEST-0
11:02:47.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=4, leaderEpoch=1, metadata=''}}
11:02:47.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 4 being sent to partition TEST-0
11:02:47.234 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=17) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:47.254 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=70): org.apache.kafka.common.requests.FetchResponse@7b64e6bc
11:02:47.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=17): org.apache.kafka.common.requests.ProduceResponse@2ed14d1
11:02:47.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 4
11:02:47.254 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:47.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 4 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=5, lastStableOffset = 5, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:47.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:47.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=14) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:47.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:47.255 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=72) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=14,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=5,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 4, CreateTime = 1662606167234, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:47.234Z)============
============ kafkacat :[kafkacat -b 10.5.0.4:9092 -L]==============
Metadata for all topics (from broker 0: 10.5.0.4:9092/0):
 2 brokers:
  broker 0 at 10.5.0.4:9092 (controller)
  broker 1 at 10.5.0.3:9092
 2 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 1, leader 1, replicas: 2,1,0, isrs: 1,0
  topic "__consumer_offsets" with 50 partitions:
    partition 0, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 1, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 2, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 3, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 4, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 5, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 6, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 7, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 8, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 9, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 10, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 11, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 12, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 13, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 14, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 15, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 16, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 17, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 18, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 19, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 20, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 21, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 22, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 23, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 24, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 25, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 26, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 27, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 28, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 29, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 30, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 31, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 32, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 33, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 34, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 35, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 36, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 37, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 38, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 39, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 40, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 41, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 42, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 43, leader 0, replicas: 0,2,1, isrs: 0,1
    partition 44, leader 1, replicas: 1,0,2, isrs: 1,0
    partition 45, leader 0, replicas: 2,0,1, isrs: 0,1
    partition 46, leader 0, replicas: 0,1,2, isrs: 0,1
    partition 47, leader 1, replicas: 1,2,0, isrs: 1,0
    partition 48, leader 1, replicas: 2,1,0, isrs: 1,0
    partition 49, leader 0, replicas: 0,2,1, isrs: 0,1
kafkaControllerId: 0
11:02:47.424 [main] INFO io.redit.samples.kafka13563.SampleTest - ============ start kafka service on server 3 ============
11:02:47.765 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=72): org.apache.kafka.common.requests.FetchResponse@d6d2770
11:02:47.765 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:47.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:47.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=15) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:47.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:47.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=73) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=15,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:48.235 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 5 being sent to partition TEST-1
11:02:48.235 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=18) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:48.245 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=18): org.apache.kafka.common.requests.ProduceResponse@dbd1eef
11:02:48.245 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 5
11:02:48.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=73): org.apache.kafka.common.requests.FetchResponse@2b46f01c
11:02:48.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:48.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:48.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=16) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:48.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:48.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=74) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=16,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=74): org.apache.kafka.common.requests.FetchResponse@1f666de7
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=5, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=17) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:48.777 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=75) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=17,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:49.235 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 5 being sent to partition TEST-0
11:02:49.235 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=19) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=75): org.apache.kafka.common.requests.FetchResponse@436b29b1
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 5 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=6, lastStableOffset = 6, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=18) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:49.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:49.245 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=76) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=18,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=6,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 5, CreateTime = 1662606169235, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:49.235Z)============
11:02:49.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=19): org.apache.kafka.common.requests.ProduceResponse@5934a3c
11:02:49.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 5
11:02:49.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=76): org.apache.kafka.common.requests.FetchResponse@27d9c00b
11:02:49.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:49.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:49.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=19) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:49.753 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:49.754 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=77) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=19,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:50.236 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 6 being sent to partition TEST-1
11:02:50.236 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=20) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:50.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=20): org.apache.kafka.common.requests.ProduceResponse@174a37dc
11:02:50.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 6
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=77): org.apache.kafka.common.requests.FetchResponse@3b8312fc
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=20) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:50.256 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=78) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=20,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:50.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=78): org.apache.kafka.common.requests.FetchResponse@1726593e
11:02:50.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:50.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=6, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:50.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=21) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:50.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:50.759 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=79) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=21,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:51.237 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 6 being sent to partition TEST-0
11:02:51.237 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=21) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:51.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=79): org.apache.kafka.common.requests.FetchResponse@d9adcca
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 6 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=7, lastStableOffset = 7, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=22) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:51.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=80) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=22,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=7,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 6, CreateTime = 1662606171236, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:51.236Z)============
11:02:51.295 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=21): org.apache.kafka.common.requests.ProduceResponse@7debe278
11:02:51.295 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 6
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=80): org.apache.kafka.common.requests.FetchResponse@64aa8cea
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=23) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:51.797 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=81) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=23,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:52.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=7, leaderEpoch=1, metadata=''}}
11:02:52.127 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=82) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=7,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:02:52.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=82): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:02:52.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 7 for partition TEST-0
11:02:52.142 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=7, leaderEpoch=1, metadata=''}}
11:02:52.237 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 7 being sent to partition TEST-1
11:02:52.238 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=22) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:52.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=22): org.apache.kafka.common.requests.ProduceResponse@1844d14c
11:02:52.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 7
11:02:52.301 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=81): org.apache.kafka.common.requests.FetchResponse@471d6671
11:02:52.301 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:52.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:52.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=24) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:52.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:52.302 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=83) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=24,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=83): org.apache.kafka.common.requests.FetchResponse@62d73805
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=7, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=25) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:52.807 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=84) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=25,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:53.238 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 7 being sent to partition TEST-0
11:02:53.239 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=23) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:53.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=84): org.apache.kafka.common.requests.FetchResponse@39f0d419
11:02:53.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:53.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 7 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=8, lastStableOffset = 8, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:53.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:53.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=26) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:53.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:53.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=85) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=26,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=8,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 7, CreateTime = 1662606173238, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:53.238Z)============
11:02:53.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=23): org.apache.kafka.common.requests.ProduceResponse@799bad2
11:02:53.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 7
11:02:53.757 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=85): org.apache.kafka.common.requests.FetchResponse@90dd211
11:02:53.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:53.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:53.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=27) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:53.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:53.758 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=86) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=27,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:54.239 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 8 being sent to partition TEST-1
11:02:54.240 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=24) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:54.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=24): org.apache.kafka.common.requests.ProduceResponse@412b992a
11:02:54.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 8
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=86): org.apache.kafka.common.requests.FetchResponse@250f03af
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=28) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:54.267 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=87) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=28,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:54.771 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=87): org.apache.kafka.common.requests.FetchResponse@7e43101b
11:02:54.772 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:54.772 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=8, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:54.772 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=29) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:54.772 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:54.772 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=88) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=29,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:55.241 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 8 being sent to partition TEST-0
11:02:55.241 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=25) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:55.265 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=88): org.apache.kafka.common.requests.FetchResponse@412c43d6
11:02:55.265 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:55.265 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 8 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=9, lastStableOffset = 9, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:55.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:55.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=30) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:55.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:55.266 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=89) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=30,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=9,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 8, CreateTime = 1662606175240, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:55.240Z)============
11:02:55.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=25): org.apache.kafka.common.requests.ProduceResponse@63714b55
11:02:55.268 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 8
11:02:55.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=89): org.apache.kafka.common.requests.FetchResponse@26569cb8
11:02:55.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:55.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:55.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=31) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:55.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:55.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=90) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=31,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:56.241 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 9 being sent to partition TEST-1
11:02:56.242 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=26) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:56.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=26): org.apache.kafka.common.requests.ProduceResponse@5d8128c6
11:02:56.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 9
11:02:56.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=90): org.apache.kafka.common.requests.FetchResponse@7b99f1a6
11:02:56.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:56.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:56.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=32) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:56.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:56.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=91) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=32,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=91): org.apache.kafka.common.requests.FetchResponse@1dbce506
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=9, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=33) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:56.785 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=92) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=33,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:57.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=9, leaderEpoch=1, metadata=''}}
11:02:57.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=93) and timeout 30000 to node 2147483647: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=9,committed_leader_epoch=1,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:02:57.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483647 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=93): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:02:57.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 9 for partition TEST-0
11:02:57.145 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=9, leaderEpoch=1, metadata=''}}
11:02:57.242 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 9 being sent to partition TEST-0
11:02:57.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=27) and timeout 30000 to node 0: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=92): org.apache.kafka.common.requests.FetchResponse@3e2d2794
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 9 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=10, lastStableOffset = 10, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=34) for node 0. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:57.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=94) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=34,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=1,fetch_offset=10,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 1, offset = 9, CreateTime = 1662606177242, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:57.242Z)============
11:02:57.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 0 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=27): org.apache.kafka.common.requests.ProduceResponse@1704568e
11:02:57.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 9
11:02:57.762 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=94): org.apache.kafka.common.requests.FetchResponse@2c0cdfb5
11:02:57.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 0 response partition(s), 1 implied partition(s)
11:02:57.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:57.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=35) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:57.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:57.763 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=95) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=35,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ kafkacat :[kafkacat -b 10.5.0.4:9092 -L]==============
Metadata for all topics (from broker 0: 10.5.0.4:9092/0):
 3 brokers:
  broker 0 at 10.5.0.4:9092 (controller)
  broker 2 at 10.5.0.2:9092
  broker 1 at 10.5.0.3:9092
 2 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 1, leader 1, replicas: 2,1,0, isrs: 1,0,2
  topic "__consumer_offsets" with 50 partitions:
    partition 0, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 1, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 2, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 3, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 4, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 5, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 6, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 7, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 8, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 9, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 10, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 11, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 12, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 13, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 14, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 15, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 16, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 17, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 18, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 19, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 20, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 21, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 22, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 23, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 24, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 25, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 26, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 27, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 28, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 29, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 30, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 31, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 32, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 33, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 34, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 35, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 36, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 37, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 38, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 39, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 40, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 41, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 42, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 43, leader 0, replicas: 0,2,1, isrs: 0,1,2
    partition 44, leader 1, replicas: 1,0,2, isrs: 1,0,2
    partition 45, leader 0, replicas: 2,0,1, isrs: 0,1,2
    partition 46, leader 0, replicas: 0,1,2, isrs: 0,1,2
    partition 47, leader 1, replicas: 1,2,0, isrs: 1,0,2
    partition 48, leader 1, replicas: 2,1,0, isrs: 1,0,2
    partition 49, leader 0, replicas: 0,2,1, isrs: 0,1,2
kafkaControllerId: 0
11:02:57.856 [main] INFO io.redit.samples.kafka13563.SampleTest - ============ shutdown kafka service on server 1 ============
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=95): org.apache.kafka.common.requests.FetchResponse@182c0f53
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=36) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.171 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.172 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:58.172 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=97) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.172 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=96) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=36,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.179 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=97): org.apache.kafka.common.requests.MetadataResponse@62424d85
11:02:58.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:58.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:58.180 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 26 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0,2, offlineReplicas=)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:58.182 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=96): org.apache.kafka.common.requests.FetchResponse@3584c7de
11:02:58.182 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.182 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.183 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.183 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.183 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=37) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.183 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.183 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=98) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=37,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.195 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=98): org.apache.kafka.common.requests.FetchResponse@7f3f47ac
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=38) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.196 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=99) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=38,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.215 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=99): org.apache.kafka.common.requests.FetchResponse@711898f
11:02:58.215 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.215 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.216 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.216 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.216 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=39) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.216 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.217 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=100) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=39,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.225 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=100): org.apache.kafka.common.requests.FetchResponse@77cfc28d
11:02:58.225 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.225 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.225 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.225 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.227 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=40) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.227 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.227 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=101) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=40,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 10 being sent to partition TEST-1
11:02:58.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=28) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=101): org.apache.kafka.common.requests.FetchResponse@6466519d
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=41) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.251 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.252 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=102) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=41,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=102): org.apache.kafka.common.requests.FetchResponse@61e1689a
11:02:58.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.257 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=42) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=103) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=42,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.280 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:58.280 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=104) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=103): org.apache.kafka.common.requests.FetchResponse@6a37c8d8
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=43) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=105) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=43,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.296 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=105): org.apache.kafka.common.requests.FetchResponse@6365a4b9
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=44) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=106) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=44,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.306 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=28): org.apache.kafka.common.requests.ProduceResponse@afb7f8d
11:02:58.306 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 10
11:02:58.310 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=106): org.apache.kafka.common.requests.FetchResponse@3559fbf1
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=45) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.311 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=107) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=45,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.314 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=104): org.apache.kafka.common.requests.MetadataResponse@5f96f078
11:02:58.314 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 1 from new metadata
11:02:58.314 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:58.315 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 27 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[0], leaderEpoch=Optional[1], replicas=0,2,1, isr=0,1,2, offlineReplicas=), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0,2, offlineReplicas=)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=107): org.apache.kafka.common.requests.FetchResponse@bb3925a
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=46) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.316 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=108) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=46,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.340 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=108): org.apache.kafka.common.requests.FetchResponse@45bdaff9
11:02:58.340 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=47) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.341 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=109) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=47,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=109): org.apache.kafka.common.requests.FetchResponse@3f4142cc
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=48) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.353 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=110) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=48,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=110): org.apache.kafka.common.requests.FetchResponse@573c706c
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=49) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.371 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=111) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=49,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=111): org.apache.kafka.common.requests.FetchResponse@400a0993
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=50) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.386 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.388 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=112) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=50,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=112): org.apache.kafka.common.requests.FetchResponse@68e0b40c
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=51) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.400 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.401 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=113) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=51,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.415 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:58.415 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=114) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=113): org.apache.kafka.common.requests.FetchResponse@5d02dcfe
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Error in fetch for partition TEST-0: org.apache.kafka.common.errors.FencedLeaderEpochException
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.4:9092 (id: 0 rack: null)], epoch=1}} to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.420 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=880843346, epoch=52) for node 0. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:58.421 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.421 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=115) and timeout 30000 to node 0: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=880843346,session_epoch=52,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.423 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=114): org.apache.kafka.common.requests.MetadataResponse@69897822
11:02:58.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 1 to epoch 2 from new metadata
11:02:58.424 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:58.425 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 28 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,2,1, isr=1,2, offlineReplicas=0), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0,2, offlineReplicas=)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:58.426 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
11:02:58.426 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
11:02:58.426 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2. Fetching API versions.
11:02:58.426 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2.
11:02:58.426 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=116) and timeout 30000 to node 2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:58.438 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 0 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=115): org.apache.kafka.common.requests.FetchResponse@5f5ce2ae
11:02:58.438 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 sent an incremental fetch response with throttleTimeMs = 0 for session 880843346 with 1 response partition(s)
11:02:58.438 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=FENCED_LEADER_EPOCH, highWaterMark=-1, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:58.438 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Ignoring fetched records for partition TEST-0 since it no longer has valid position
11:02:58.480 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=116): org.apache.kafka.common.requests.ApiVersionsResponse@7d36c90f
11:02:58.481 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:58.483 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_FOR_LEADER_EPOCH request with header RequestHeader(apiKey=OFFSET_FOR_LEADER_EPOCH, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=117) and timeout 30000 to node 2: {replica_id=-1,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,leader_epoch=1}]}]}
11:02:58.486 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_FOR_LEADER_EPOCH response from node 2 for request with header RequestHeader(apiKey=OFFSET_FOR_LEADER_EPOCH, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=117): (type=OffsetsForLeaderEpochResponse, , throttleTimeMs=0, epochEndOffsetsByPartition={TEST-0=EpochEndOffset{error=NONE, leaderEpoch=1, endOffset=10}})
11:02:58.486 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.OffsetsForLeaderEpochClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Handling OffsetsForLeaderEpoch response for TEST-0. Got offset 10 for epoch 1
11:02:58.488 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:02:58.488 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 2 with 1 partition(s).
11:02:58.488 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED FullFetchRequest(TEST-0) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:02:58.488 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=118) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=0,session_epoch=0,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=10,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:58.529 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:325)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:240)
	at java.lang.Thread.run(Thread.java:750)
11:02:58.529 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Node 0 disconnected.
11:02:58.529 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:58.530 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=29) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.529 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1292)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1233)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:141)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
11:02:58.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2147483647 disconnected.
11:02:58.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.4:9092 (id: 0 rack: null)
11:02:58.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=119) and timeout 30000 to node 0: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.530 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:97)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:447)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:397)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:674)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:576)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1292)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1233)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:141)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
11:02:58.530 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 0 disconnected.
11:02:58.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=29): org.apache.kafka.common.requests.MetadataResponse@63b9b664
11:02:58.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-0 from 1 to epoch 2 from new metadata
11:02:58.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-1 from 1 to epoch 1 from new metadata
11:02:58.534 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 5 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,2,1, isr=1,2, offlineReplicas=0), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[1], replicas=2,1,0, isr=1,0,2, offlineReplicas=)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:58.630 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:02:58.630 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=120) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:02:58.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=120): org.apache.kafka.common.requests.MetadataResponse@223b0675
11:02:58.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 2 to epoch 2 from new metadata
11:02:58.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 1 to epoch 2 from new metadata
11:02:58.632 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 29 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={0=10.5.0.4:9092 (id: 0 rack: null), 1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,2,1, isr=1,2, offlineReplicas=0), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[2], replicas=2,1,0, isr=1,2, offlineReplicas=0)], controller=10.5.0.4:9092 (id: 0 rack: null)}
11:02:59.054 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=118): org.apache.kafka.common.requests.FetchResponse@4d78deaf
11:02:59.054 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent a full fetch response that created a new incremental fetch session 100756333 with 1 response partition(s)
11:02:59.054 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=10, lastStableOffset = 10, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=0)
11:02:59.054 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=10, offsetEpoch=Optional[1], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.054 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=1) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:59.055 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.055 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=121) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=1,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:02:59.243 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating connection to node 10.5.0.2:9092 (id: 2 rack: null) using address /10.5.0.2
11:02:59.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.common.network.Selector - [Producer clientId=producer-1] Created socket with SO_RCVBUF = 32768, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2
11:02:59.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Completed connection to node 2. Fetching API versions.
11:02:59.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Initiating API versions fetch from node 2.
11:02:59.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=30) and timeout 30000 to node 2: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:02:59.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received API_VERSIONS response from node 2 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=producer-1, correlationId=30): org.apache.kafka.common.requests.ApiVersionsResponse@22fe590
11:02:59.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Recorded API versions for node 2: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:02:59.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 10 being sent to partition TEST-0
11:02:59.247 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=31) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=121): org.apache.kafka.common.requests.FetchResponse@5172ed71
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 10 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=11, lastStableOffset = 11, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=2) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.313 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=122) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=2,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=11,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 10, CreateTime = 1662606179243, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:02:59.243Z)============
11:02:59.323 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=31): org.apache.kafka.common.requests.ProduceResponse@53f9e54f
11:02:59.323 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 10
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=122): org.apache.kafka.common.requests.FetchResponse@3dbbbb27
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=3) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:02:59.821 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=123) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=3,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:00.244 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 11 being sent to partition TEST-1
11:03:00.245 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=32) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:00.253 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=32): org.apache.kafka.common.requests.ProduceResponse@7d5d73c2
11:03:00.253 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 11
11:03:00.325 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=123): org.apache.kafka.common.requests.FetchResponse@47c90a4b
11:03:00.326 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:00.326 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:00.326 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=4) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:00.326 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:00.326 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=124) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=4,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:00.832 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=124): org.apache.kafka.common.requests.FetchResponse@4ccf39bb
11:03:00.832 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:00.833 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=11, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:00.833 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=5) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:00.833 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:00.833 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=125) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=5,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:01.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 11 being sent to partition TEST-0
11:03:01.246 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=33) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:01.258 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=125): org.apache.kafka.common.requests.FetchResponse@a904c36
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 11 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=12, lastStableOffset = 12, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=6) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:01.259 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=126) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=6,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=12,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 11, CreateTime = 1662606181245, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:01.245Z)============
11:03:01.269 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=33): org.apache.kafka.common.requests.ProduceResponse@193de5a9
11:03:01.269 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 11
11:03:01.765 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=126): org.apache.kafka.common.requests.FetchResponse@6a92acc0
11:03:01.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:01.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:01.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=7) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:01.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:01.766 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=127) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=7,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:02.128 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
11:03:02.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.4:9092 (id: 2147483647 rack: null) using address /10.5.0.4
11:03:02.129 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection with /10.5.0.4 disconnected
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:716)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:219)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:526)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:481)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:563)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:265)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:306)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsAsync(ConsumerCoordinator.java:953)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.doAutoCommitOffsetsAsync(ConsumerCoordinator.java:1041)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.maybeAutoCommitOffsetsAsync(ConsumerCoordinator.java:1032)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:529)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1257)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1226)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1206)
	at io.redit.samples.kafka13563.SampleTest.lambda$testConsumerAssign$1(SampleTest.java:141)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
11:03:02.129 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2147483647 disconnected.
11:03:02.129 [pool-6-thread-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Connection to node 2147483647 (/10.5.0.4:9092) could not be established. Broker may not be available.
11:03:02.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Cancelled request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=128) due to node 2147483647 being disconnected
11:03:02.130 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Group coordinator 10.5.0.4:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: null.isDisconnected: true. Rediscovery will be attempted.
11:03:02.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:03:02.130 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=129) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:03:02.131 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}} failed due to retriable error: {}
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.common.errors.DisconnectException: null
11:03:02.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=consumer-TestGroup-1, correlationId=129): org.apache.kafka.common.requests.MetadataResponse@50b19761
11:03:02.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-0 from 2 to epoch 2 from new metadata
11:03:02.138 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updating last seen epoch for partition TEST-1 from 2 to epoch 2 from new metadata
11:03:02.139 [pool-6-thread-1] DEBUG org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Updated cluster metadata updateVersion 30 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,2,1, isr=1,2, offlineReplicas=0), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[1], leaderEpoch=Optional[2], replicas=2,1,0, isr=1,2, offlineReplicas=0)], controller=10.5.0.3:9092 (id: 1 rack: null)}
11:03:02.231 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
11:03:02.232 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FindCoordinator request to broker 10.5.0.3:9092 (id: 1 rack: null)
11:03:02.232 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FIND_COORDINATOR request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=130) and timeout 30000 to node 1: {key=TestGroup,key_type=0,_tagged_fields={}}
11:03:02.235 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FIND_COORDINATOR response from node 1 for request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=130): FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=2, host='10.5.0.2', port=9092)
11:03:02.235 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FindCoordinator response ClientResponse(receivedTimeMs=1662606182235, latencyMs=3, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=130), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='NONE', nodeId=2, host='10.5.0.2', port=9092))
11:03:02.235 [pool-6-thread-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Discovered group coordinator 10.5.0.2:9092 (id: 2147483645 rack: null)
11:03:02.235 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating connection to node 10.5.0.2:9092 (id: 2147483645 rack: null) using address /10.5.0.2
11:03:02.239 [pool-6-thread-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 131072, SO_TIMEOUT = 0 to node 2147483645
11:03:02.239 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed connection to node 2147483645. Fetching API versions.
11:03:02.239 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Initiating API versions fetch from node 2147483645.
11:03:02.239 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending API_VERSIONS request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=132) and timeout 30000 to node 2147483645: {client_software_name=apache-kafka-java,client_software_version=2.7.1,_tagged_fields={}}
11:03:02.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received API_VERSIONS response from node 2147483645 for request with header RequestHeader(apiKey=API_VERSIONS, apiVersion=3, clientId=consumer-TestGroup-1, correlationId=132): org.apache.kafka.common.requests.ApiVersionsResponse@51449f5c
11:03:02.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Recorded API versions for node 2147483645: (Produce(0): 0 to 8 [usable: 8], Fetch(1): 0 to 12 [usable: 12], ListOffsets(2): 0 to 5 [usable: 5], Metadata(3): 0 to 9 [usable: 9], LeaderAndIsr(4): 0 to 4 [usable: 4], StopReplica(5): 0 to 3 [usable: 3], UpdateMetadata(6): 0 to 6 [usable: 6], ControlledShutdown(7): 0 to 3 [usable: 3], OffsetCommit(8): 0 to 8 [usable: 8], OffsetFetch(9): 0 to 7 [usable: 7], FindCoordinator(10): 0 to 3 [usable: 3], JoinGroup(11): 0 to 7 [usable: 7], Heartbeat(12): 0 to 4 [usable: 4], LeaveGroup(13): 0 to 4 [usable: 4], SyncGroup(14): 0 to 5 [usable: 5], DescribeGroups(15): 0 to 5 [usable: 5], ListGroups(16): 0 to 4 [usable: 4], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 3 [usable: 3], CreateTopics(19): 0 to 6 [usable: 6], DeleteTopics(20): 0 to 5 [usable: 5], DeleteRecords(21): 0 to 2 [usable: 2], InitProducerId(22): 0 to 4 [usable: 4], OffsetForLeaderEpoch(23): 0 to 3 [usable: 3], AddPartitionsToTxn(24): 0 to 2 [usable: 2], AddOffsetsToTxn(25): 0 to 2 [usable: 2], EndTxn(26): 0 to 2 [usable: 2], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 3 [usable: 3], DescribeAcls(29): 0 to 2 [usable: 2], CreateAcls(30): 0 to 2 [usable: 2], DeleteAcls(31): 0 to 2 [usable: 2], DescribeConfigs(32): 0 to 3 [usable: 3], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 2 [usable: 2], SaslAuthenticate(36): 0 to 2 [usable: 2], CreatePartitions(37): 0 to 3 [usable: 3], CreateDelegationToken(38): 0 to 2 [usable: 2], RenewDelegationToken(39): 0 to 2 [usable: 2], ExpireDelegationToken(40): 0 to 2 [usable: 2], DescribeDelegationToken(41): 0 to 2 [usable: 2], DeleteGroups(42): 0 to 2 [usable: 2], ElectLeaders(43): 0 to 2 [usable: 2], IncrementalAlterConfigs(44): 0 to 1 [usable: 1], AlterPartitionReassignments(45): 0 [usable: 0], ListPartitionReassignments(46): 0 [usable: 0], OffsetDelete(47): 0 [usable: 0], DescribeClientQuotas(48): 0 [usable: 0], AlterClientQuotas(49): 0 [usable: 0], DescribeUserScramCredentials(50): 0 [usable: 0], AlterUserScramCredentials(51): 0 [usable: 0], AlterIsr(56): 0 [usable: 0], UpdateFeatures(57): 0 [usable: 0])
11:03:02.243 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=131) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=12,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:03:02.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 12 being sent to partition TEST-1
11:03:02.251 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=34) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:02.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=34): org.apache.kafka.common.requests.ProduceResponse@64c3807b
11:03:02.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 12
11:03:02.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=127): org.apache.kafka.common.requests.FetchResponse@7fec1d31
11:03:02.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:02.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:02.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=8) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:02.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:02.272 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=133) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=8,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:02.281 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=131): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:03:02.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 12 for partition TEST-0
11:03:02.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=12, leaderEpoch=2, metadata=''}}
11:03:02.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=133): org.apache.kafka.common.requests.FetchResponse@19891fe
11:03:02.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:02.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=12, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:02.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=9) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:02.779 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:02.779 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=134) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=9,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:03.252 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 12 being sent to partition TEST-0
11:03:03.252 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=35) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=134): org.apache.kafka.common.requests.FetchResponse@46ea4883
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 12 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=13, lastStableOffset = 13, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=10) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:03.268 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=135) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=10,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=13,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 12, CreateTime = 1662606183252, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:03.251Z)============
11:03:03.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=35): org.apache.kafka.common.requests.ProduceResponse@788cd231
11:03:03.271 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 12
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=135): org.apache.kafka.common.requests.FetchResponse@33a1817d
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=11) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:03.773 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=136) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=11,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:04.253 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 13 being sent to partition TEST-1
11:03:04.253 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=36) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:04.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=36): org.apache.kafka.common.requests.ProduceResponse@6e597d81
11:03:04.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 13
11:03:04.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=136): org.apache.kafka.common.requests.FetchResponse@2c3b07ad
11:03:04.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:04.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:04.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=12) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:04.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:04.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=137) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=12,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:04.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=137): org.apache.kafka.common.requests.FetchResponse@696974b5
11:03:04.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:04.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:04.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=13) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:04.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:04.784 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=138) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=13,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:05.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 13 being sent to partition TEST-0
11:03:05.254 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=37) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:05.287 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=138): org.apache.kafka.common.requests.FetchResponse@7dd3874b
11:03:05.287 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:05.287 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=13, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.287 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=14) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:05.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.288 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=139) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=14,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:05.296 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=139): org.apache.kafka.common.requests.FetchResponse@42c64be5
11:03:05.296 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:05.296 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 13 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=14, lastStableOffset = 14, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:05.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=15) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:05.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.297 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=140) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=15,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=14,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 13, CreateTime = 1662606185253, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:05.253Z)============
11:03:05.300 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=37): org.apache.kafka.common.requests.ProduceResponse@18bfcd4e
11:03:05.300 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 13
11:03:05.802 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=140): org.apache.kafka.common.requests.FetchResponse@36343a7f
11:03:05.802 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:05.803 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.803 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=16) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:05.803 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:05.803 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=141) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=16,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:06.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 14 being sent to partition TEST-1
11:03:06.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=38) and timeout 30000 to node 1: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:06.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 1 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=38): org.apache.kafka.common.requests.ProduceResponse@6087467a
11:03:06.260 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Got error produce response with correlation id 38 on topic-partition TEST-1, retrying (2147483646 attempts left). Error: NOT_LEADER_OR_FOLLOWER
11:03:06.260 [kafka-producer-network-thread | producer-1] WARN org.apache.kafka.clients.producer.internals.Sender - [Producer clientId=producer-1] Received invalid metadata error in produce request on partition TEST-1 due to org.apache.kafka.common.errors.NotLeaderOrFollowerException: For requests intended only for the leader, this error indicates that the broker is not the current leader. For requests intended for any replica, this error indicates that the broker is not a replica of the topic partition.. Going to request metadata update now
11:03:06.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='TEST')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node 10.5.0.3:9092 (id: 1 rack: null)
11:03:06.261 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending METADATA request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=39) and timeout 30000 to node 1: {topics=[{name=TEST,_tagged_fields={}}],allow_auto_topic_creation=true,include_cluster_authorized_operations=false,include_topic_authorized_operations=false,_tagged_fields={}}
11:03:06.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received METADATA response from node 1 for request with header RequestHeader(apiKey=METADATA, apiVersion=9, clientId=producer-1, correlationId=39): org.apache.kafka.common.requests.MetadataResponse@7e840d01
11:03:06.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-0 from 2 to epoch 2 from new metadata
11:03:06.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updating last seen epoch for partition TEST-1 from 1 to epoch 3 from new metadata
11:03:06.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Updated cluster metadata updateVersion 6 to MetadataCache{clusterId='-xzXV6INQZuCQMvamkAusg', nodes={1=10.5.0.3:9092 (id: 1 rack: null), 2=10.5.0.2:9092 (id: 2 rack: null)}, partitions=[PartitionMetadata(error=NONE, partition=TEST-0, leader=Optional[2], leaderEpoch=Optional[2], replicas=0,2,1, isr=1,2, offlineReplicas=0), PartitionMetadata(error=NONE, partition=TEST-1, leader=Optional[2], leaderEpoch=Optional[3], replicas=2,1,0, isr=1,2, offlineReplicas=0)], controller=10.5.0.3:9092 (id: 1 rack: null)}
11:03:06.305 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=141): org.apache.kafka.common.requests.FetchResponse@14da2cd0
11:03:06.305 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:06.305 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:06.305 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=17) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:06.305 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:06.306 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=142) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=17,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:06.361 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=40) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:06.381 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=40): org.apache.kafka.common.requests.ProduceResponse@5b94c225
11:03:06.381 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 14
11:03:06.808 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=142): org.apache.kafka.common.requests.FetchResponse@75d218df
11:03:06.808 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:06.810 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=14, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:06.810 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=18) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:06.810 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:06.810 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=143) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=18,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:07.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=14, leaderEpoch=2, metadata=''}}
11:03:07.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=144) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=14,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:03:07.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=144): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:03:07.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 14 for partition TEST-0
11:03:07.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=14, leaderEpoch=2, metadata=''}}
11:03:07.255 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 14 being sent to partition TEST-0
11:03:07.256 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=41) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:07.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=41): org.apache.kafka.common.requests.ProduceResponse@3d27b1a4
11:03:07.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 14
11:03:07.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=143): org.apache.kafka.common.requests.FetchResponse@5bbfce3
11:03:07.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:07.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 14 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=15, lastStableOffset = 15, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:07.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=15, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:07.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=19) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:07.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:07.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=145) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=19,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=15,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 14, CreateTime = 1662606187255, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:07.255Z)============
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=145): org.apache.kafka.common.requests.FetchResponse@12cbd9e9
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=15, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=20) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:07.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=146) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=20,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:08.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 15 being sent to partition TEST-1
11:03:08.257 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=42) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:08.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=42): org.apache.kafka.common.requests.ProduceResponse@67c984ec
11:03:08.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 15
11:03:08.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=146): org.apache.kafka.common.requests.FetchResponse@57b2dbcc
11:03:08.282 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:08.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=15, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:08.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=21) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:08.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:08.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=147) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=21,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:08.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=147): org.apache.kafka.common.requests.FetchResponse@32c32505
11:03:08.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:08.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=15, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:08.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=22) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:08.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:08.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=148) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=22,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:09.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 15 being sent to partition TEST-0
11:03:09.258 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=43) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:09.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=148): org.apache.kafka.common.requests.FetchResponse@68459b5a
11:03:09.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:09.273 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 15 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=16, lastStableOffset = 16, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:09.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=16, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:09.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=23) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:09.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:09.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=149) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=23,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=16,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 15, CreateTime = 1662606189258, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:09.257Z)============
11:03:09.275 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=43): org.apache.kafka.common.requests.ProduceResponse@397b7111
11:03:09.275 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 15
11:03:09.778 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=149): org.apache.kafka.common.requests.FetchResponse@248d132a
11:03:09.779 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:09.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=16, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:09.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=24) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:09.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:09.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=150) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=24,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:10.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 16 being sent to partition TEST-1
11:03:10.259 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=44) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:10.267 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=44): org.apache.kafka.common.requests.ProduceResponse@448309f1
11:03:10.268 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 16
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=150): org.apache.kafka.common.requests.FetchResponse@6520c0cc
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=16, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=25) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:10.284 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=151) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=25,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:10.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=151): org.apache.kafka.common.requests.FetchResponse@4ee03a60
11:03:10.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:10.788 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=16, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:10.788 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=26) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:10.788 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:10.788 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=152) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=26,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:11.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 16 being sent to partition TEST-0
11:03:11.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=45) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:11.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=152): org.apache.kafka.common.requests.FetchResponse@abbf7ad
11:03:11.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:11.269 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 16 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=17, lastStableOffset = 17, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:11.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=17, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:11.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=27) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:11.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:11.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=153) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=27,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=17,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 16, CreateTime = 1662606191259, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:11.259Z)============
11:03:11.274 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=45): org.apache.kafka.common.requests.ProduceResponse@44a92a54
11:03:11.274 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 16
11:03:11.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=153): org.apache.kafka.common.requests.FetchResponse@46e3a193
11:03:11.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:11.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=17, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:11.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=28) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:11.774 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:11.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=154) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=28,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:12.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=17, leaderEpoch=2, metadata=''}}
11:03:12.233 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=155) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=17,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:03:12.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=155): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:03:12.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 17 for partition TEST-0
11:03:12.242 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=17, leaderEpoch=2, metadata=''}}
11:03:12.260 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 17 being sent to partition TEST-1
11:03:12.261 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=46) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:12.268 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=46): org.apache.kafka.common.requests.ProduceResponse@6fec28c9
11:03:12.269 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 17
11:03:12.277 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=154): org.apache.kafka.common.requests.FetchResponse@25262f23
11:03:12.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:12.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=17, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:12.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=29) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:12.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:12.278 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=156) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=29,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=156): org.apache.kafka.common.requests.FetchResponse@6ada32dd
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=17, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=30) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:12.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=157) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=30,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:13.262 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 17 being sent to partition TEST-0
11:03:13.262 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=47) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:13.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=157): org.apache.kafka.common.requests.FetchResponse@3f09a6b4
11:03:13.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:13.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 17 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=18, lastStableOffset = 18, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:13.276 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=18, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:13.276 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=31) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:13.276 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:13.276 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=158) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=31,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=18,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 17, CreateTime = 1662606193261, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:13.261Z)============
11:03:13.279 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=47): org.apache.kafka.common.requests.ProduceResponse@d7d3fdc
11:03:13.279 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 17
11:03:13.779 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=158): org.apache.kafka.common.requests.FetchResponse@64bd67ff
11:03:13.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:13.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=18, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:13.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=32) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:13.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:13.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=159) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=32,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:14.263 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 18 being sent to partition TEST-1
11:03:14.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=48) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:14.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=48): org.apache.kafka.common.requests.ProduceResponse@516d6303
11:03:14.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 18
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=159): org.apache.kafka.common.requests.FetchResponse@7076137c
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=18, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=33) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:14.283 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=160) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=33,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:14.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=160): org.apache.kafka.common.requests.FetchResponse@4b818b75
11:03:14.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:14.786 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=18, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:14.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=34) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:14.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:14.787 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=161) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=34,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:15.263 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 18 being sent to partition TEST-0
11:03:15.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=49) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:15.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=161): org.apache.kafka.common.requests.FetchResponse@394fa8b7
11:03:15.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:15.270 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 18 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=19, lastStableOffset = 19, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:15.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=19, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:15.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=35) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:15.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:15.271 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=162) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=35,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=19,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 18, CreateTime = 1662606195263, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:15.263Z)============
11:03:15.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=49): org.apache.kafka.common.requests.ProduceResponse@5c9b18f0
11:03:15.272 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 18
11:03:15.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=162): org.apache.kafka.common.requests.FetchResponse@36c2b2fe
11:03:15.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:15.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=19, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:15.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=36) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:15.775 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:15.776 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=163) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=36,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:16.264 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 19 being sent to partition TEST-1
11:03:16.265 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=50) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-1=92]}
11:03:16.273 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=50): org.apache.kafka.common.requests.ProduceResponse@52bfd9ca
11:03:16.273 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-1 to 19
11:03:16.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=163): org.apache.kafka.common.requests.FetchResponse@76efaaa9
11:03:16.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:16.279 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=19, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:16.280 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=37) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:16.280 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:16.280 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=164) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=37,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:16.782 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=164): org.apache.kafka.common.requests.FetchResponse@31f24d22
11:03:16.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:16.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=19, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:16.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=38) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:16.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:16.783 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=165) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=38,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
11:03:17.235 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=19, leaderEpoch=2, metadata=''}}
11:03:17.235 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending OFFSET_COMMIT request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=166) and timeout 30000 to node 2147483645: {group_id=TestGroup,generation_id=-1,member_id=,group_instance_id=null,topics=[{name=TEST,partitions=[{partition_index=0,committed_offset=19,committed_leader_epoch=2,committed_metadata=,_tagged_fields={}}],_tagged_fields={}}],_tagged_fields={}}
11:03:17.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received OFFSET_COMMIT response from node 2147483645 for request with header RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=8, clientId=consumer-TestGroup-1, correlationId=166): OffsetCommitResponseData(throttleTimeMs=0, topics=[OffsetCommitResponseTopic(name='TEST', partitions=[OffsetCommitResponsePartition(partitionIndex=0, errorCode=0)])])
11:03:17.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Committed offset 19 for partition TEST-0
11:03:17.244 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Completed asynchronous auto-commit of offsets {TEST-0=OffsetAndMetadata{offset=19, leaderEpoch=2, metadata=''}}
11:03:17.265 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.RecordAccumulator - [Producer clientId=producer-1] Assigned producerId 0 and producerEpoch 0 to batch with base sequence 19 being sent to partition TEST-0
11:03:17.265 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Sending PRODUCE request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=51) and timeout 30000 to node 2: {acks=-1,timeout=30000,partitionSizes=[TEST-0=92]}
11:03:17.274 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.NetworkClient - [Producer clientId=producer-1] Received PRODUCE response from node 2 for request with header RequestHeader(apiKey=PRODUCE, apiVersion=8, clientId=producer-1, correlationId=51): org.apache.kafka.common.requests.ProduceResponse@36589f9e
11:03:17.274 [kafka-producer-network-thread | producer-1] DEBUG org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId: 0; Set last ack'd sequence number for topic-partition TEST-0 to 19
11:03:17.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=165): org.apache.kafka.common.requests.FetchResponse@75bc51bb
11:03:17.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 1 response partition(s)
11:03:17.274 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Fetch READ_UNCOMMITTED at offset 19 for partition TEST-0 returned fetch data (error=NONE, highWaterMark=20, lastStableOffset = 20, logStartOffset = 0, preferredReadReplica = absent, abortedTransactions = null, divergingEpoch =Optional.empty, recordsSizeInBytes=92)
11:03:17.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=20, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:17.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=39) for node 2. Added 0 partition(s), altered 1 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:17.275 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(TEST-0), toForget=(), implied=()) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:17.276 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=167) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=39,topics=[{topic=TEST,partitions=[{partition=0,current_leader_epoch=2,fetch_offset=20,last_fetched_epoch=-1,log_start_offset=-1,partition_max_bytes=1048576,_tagged_fields={}}],_tagged_fields={}}],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ConsumerRecord(topic = TEST, partition = 0, leaderEpoch = 2, offset = 19, CreateTime = 1662606197265, serialized key size = -1, serialized value size = 24, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 2022-09-08T03:03:17.265Z)============
11:03:17.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Received FETCH response from node 2 for request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=167): org.apache.kafka.common.requests.FetchResponse@56ca48b0
11:03:17.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Node 2 sent an incremental fetch response with throttleTimeMs = 0 for session 100756333 with 0 response partition(s), 1 implied partition(s)
11:03:17.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Added READ_UNCOMMITTED fetch request for partition TEST-0 at position FetchPosition{offset=20, offsetEpoch=Optional[2], currentLeader=LeaderAndEpoch{leader=Optional[10.5.0.2:9092 (id: 2 rack: null)], epoch=2}} to node 10.5.0.2:9092 (id: 2 rack: null)
11:03:17.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Built incremental fetch (sessionId=100756333, epoch=40) for node 2. Added 0 partition(s), altered 0 partition(s), removed 0 partition(s) out of 1 partition(s)
11:03:17.780 [pool-6-thread-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending READ_UNCOMMITTED IncrementalFetchRequest(toSend=(), toForget=(), implied=(TEST-0)) to broker 10.5.0.2:9092 (id: 2 rack: null)
11:03:17.781 [pool-6-thread-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-TestGroup-1, groupId=TestGroup] Sending FETCH request with header RequestHeader(apiKey=FETCH, apiVersion=12, clientId=consumer-TestGroup-1, correlationId=168) and timeout 30000 to node 2: {replica_id=-1,max_wait_ms=500,min_bytes=1,max_bytes=52428800,isolation_level=0,session_id=100756333,session_epoch=40,topics=[],forgotten_topics_data=[],rack_id=,_tagged_fields={}}
============ kafkacat :[kafkacat -b 10.5.0.3:9092 -L]==============
Metadata for all topics (from broker 1: 10.5.0.3:9092/1):
 2 brokers:
  broker 2 at 10.5.0.2:9092
  broker 1 at 10.5.0.3:9092 (controller)
 2 topics:
  topic "TEST" with 2 partitions:
    partition 0, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 1, leader 2, replicas: 2,1,0, isrs: 1,2
  topic "__consumer_offsets" with 50 partitions:
    partition 0, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 1, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 2, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 3, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 4, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 5, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 6, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 7, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 8, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 9, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 10, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 11, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 12, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 13, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 14, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 15, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 16, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 17, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 18, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 19, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 20, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 21, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 22, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 23, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 24, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 25, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 26, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 27, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 28, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 29, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 30, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 31, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 32, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 33, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 34, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 35, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 36, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 37, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 38, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 39, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 40, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 41, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 42, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 43, leader 2, replicas: 0,2,1, isrs: 1,2
    partition 44, leader 1, replicas: 1,0,2, isrs: 1,2
    partition 45, leader 2, replicas: 2,0,1, isrs: 1,2
    partition 46, leader 1, replicas: 0,1,2, isrs: 1,2
    partition 47, leader 1, replicas: 1,2,0, isrs: 1,2
    partition 48, leader 2, replicas: 2,1,0, isrs: 1,2
    partition 49, leader 2, replicas: 0,2,1, isrs: 1,2
kafkaControllerId: 1
11:03:17.969 [main] INFO io.redit.samples.kafka13563.SampleTest - completed !!!
